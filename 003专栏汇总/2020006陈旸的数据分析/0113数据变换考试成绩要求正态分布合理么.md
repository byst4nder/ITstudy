# 0113 数据变换：考试成绩要求正态分布合理么？

陈旸 2019-01-11




10:19


讲述：陈旸 大小：9.46M

上一讲中我给你讲了数据集成，今天我来讲下数据变换。

如果一个人在百分制的考试中得了 95 分，你肯定会认为他学习成绩很好，如果得了 65 分，就会觉得他成绩不好。如果得了 80 分呢？你会觉得他成绩中等，因为在班级里这属于大部分人的情况。

为什么会有这样的认知呢？这是因为我们从小到大的考试成绩基本上都会满足正态分布的情况。什么是正态分布呢？正态分布也叫作常态分布，就是正常的状态下，呈现的分布情况。

比如你可能会问班里的考试成绩是怎样的？这里其实指的是大部分同学的成绩如何。以下图为例，在正态分布中，大部分人的成绩会集中在中间的区域，少部分人处于两头的位置。正态分布的另一个好处就是，如果你知道了自己的成绩，和整体的正态分布情况，就可以知道自己的成绩在全班中的位置。

另一个典型的例子就是，美国 SAT 考试成绩也符合正态分布。而且美国本科的申请，需要中国高中生的 GPA 在 80 分以上（百分制的成绩），背后的理由也是默认考试成绩属于正态分布的情况。

为了让成绩符合正态分布，出题老师是怎么做的呢？他们通常可以把考题分成三类：

第一类：基础题，占总分 70%，基本上属于送分题；

第二类：灵活题，基础范围内 + 一定的灵活性，占 20%；

第三类：难题，涉及知识面较广的难题，占 10%；

那么，你想下，如果一个出题老师没有按照上面的标准来出题，而是将第三类难题比重占到了 70%，也就是我们说的「超纲」，结果会是怎样呢？

你会发现，大部分人成绩都「不及格」，最后在大家激烈的讨论声中，老师会将考试成绩做规范化处理，从而让成绩满足正态分布的情况。因为只有这样，成绩才更具有比较性。所以正态分布的成绩，不仅可以让你了解全班整体的情况，还能了解每个人的成绩在全班中的位置。

数据变换在数据分析中的角色

我们再来举个例子，假设 A 考了 80 分，B 也考了 80 分，但前者是百分制，后者 500 分是满分，如果我们把从这两个渠道收集上来的数据进行集成、挖掘，就算使用效率再高的算法，结果也不是正确的。因为这两个渠道的分数代表的含义完全不同。

所以说，有时候数据变换比算法选择更重要，数据错了，算法再正确也是错的。你现在可以理解为什么 80% 的工作时间会花在前期的数据准备上了吧。

那么如何让不同渠道的数据统一到一个目标数据库里呢？这样就用到了数据变换。

在数据变换前，我们需要先对字段进行筛选，然后对数据进行探索和相关性分析，接着是选择算法模型（这里暂时不需要进行模型计算），然后针对算法模型对数据的需求进行数据变换，从而完成数据挖掘前的准备工作。

所以你从整个流程中可以看出，数据变换是数据准备的重要环节，它通过数据平滑、数据聚集、数据概化和规范化等方式将数据转换成适用于数据挖掘的形式。

我来介绍下这些常见的变换方法：

数据平滑：去除数据中的噪声，将连续数据离散化。这里可以采用分箱、聚类和回归的方式进行数据平滑，我会在后面给你讲解聚类和回归这两个算法；

数据聚集：对数据进行汇总，在 SQL 中有一些聚集函数可以供我们操作，比如 Max () 反馈某个字段的数值最大值，Sum () 返回某个字段的数值总和；

数据概化：将数据由较低的概念抽象成为较高的概念，减少数据复杂度，即用更高的概念替代更低的概念。比如说上海、杭州、深圳、北京可以概化为中国。

数据规范化：使属性数据按比例缩放，这样就将原来的数值映射到一个新的特定区域中。常用的方法有最小 — 最大规范化、Z—score 规范化、按小数定标规范化等，我会在后面给你讲到这些方法的使用；

属性构造：构造出新的属性并添加到属性集中。这里会用到特征工程的知识，因为通过属性与属性的连接构造新的属性，其实就是特征工程。比如说，数据表中统计每个人的英语、语文和数学成绩，你可以构造一个「总和」这个属性，来作为新属性。这样「总和」这个属性就可以用到后续的数据挖掘计算中。

在这些变换方法中，最简单易用的就是对数据进行规范化处理。下面我来给你讲下如何对数据进行规范化处理。

数据规范化的几种方法

1. Min-max 规范化

Min-max 规范化方法是将原始数据变换到 [0,1] 的空间中。用公式表示就是：

新数值 =（原数值 - 极小值）/（极大值 - 极小值）。

2. Z-Score 规范化

假设 A 与 B 的考试成绩都为 80 分，A 的考卷满分是 100 分（及格 60 分），B 的考卷满分是 500 分（及格 300 分）。虽然两个人都考了 80 分，但是 A 的 80 分与 B 的 80 分代表完全不同的含义。

那么如何用相同的标准来比较 A 与 B 的成绩呢？Z-Score 就是用来可以解决这一问题的。

我们定义：新数值 =（原数值 - 均值）/ 标准差。

假设 A 所在的班级平均分为 80，标准差为 10。B 所在的班级平均分为 400，标准差为 100。那么 A 的新数值 =(80-80)/10=0，B 的新数值 =(80-400)/100=-3.2。

那么在 Z-Score 标准下，A 的成绩会比 B 的成绩好。

我们能看到 Z-Score 的优点是算法简单，不受数据量级影响，结果易于比较。不足在于，它需要数据整体的平均值和方差，而且结果没有实际意义，只是用于比较。

3. 小数定标规范化

小数定标规范化就是通过移动小数点的位置来进行规范化。小数点移动多少位取决于属性 A 的取值中的最大绝对值。

举个例子，比如属性 A 的取值范围是 -999 到 88，那么最大绝对值为 999，小数点就会移动 3 位，即新数值 = 原数值 /1000。那么 A 的取值范围就被规范化为 -0.999 到 0.088。

上面这三种是数值规范化中常用的几种方式。

Python 的 SciKit-Learn 库使用

SciKit-Learn 是 Python 的重要机器学习库，它帮我们封装了大量的机器学习算法，比如分类、聚类、回归、降维等。此外，它还包括了数据变换模块。

我现在来讲下如何使用 SciKit-Learn 进行数据规范化。

1. Min-max 规范化

我们可以让原始数据投射到指定的空间 [min, max]，在 SciKit-Learn 里有个函数 MinMaxScaler 是专门做这个的，它允许我们给定一个最大值与最小值，然后将原数据投射到 [min, max] 中。默认情况下 [min,max] 是 [0,1]，也就是把原始数据投放到 [0,1] 范围内。

我们来看下下面这个例子：

# coding:utf-8


from sklearn import preprocessing


import numpy as np


# 初始化数据，每一行表示一个样本，每一列表示一个特征

x = np.array([[ 0., -3.,  1.],


              [ 3.,  1.,  2.],


              [ 0.,  1., -1.]])


# 将数据进行 [0,1] 规范化

min_max_scaler = preprocessing.MinMaxScaler()


minmax_x = min_max_scaler.fit_transform(x)


print minmax_x


运行结果：

[[0.         0.         0.66666667]


 [1.         1.         1.        ]


 [0.         1.         0.        ]]


2. Z-Score 规范化

在 SciKit-Learn 库中使用 preprocessing.scale () 函数，可以直接将给定数据进行 Z-Score 规范化。

from sklearn import preprocessing


import numpy as np


# 初始化数据

x = np.array([[ 0., -3.,  1.],


              [ 3.,  1.,  2.],


              [ 0.,  1., -1.]])


# 将数据进行 Z-Score 规范化

scaled_x = preprocessing.scale(x)


print scaled_x


运行结果：

[[-0.70710678 -1.41421356  0.26726124]


 [ 1.41421356  0.70710678  1.06904497]


 [-0.70710678  0.70710678 -1.33630621]]


这个结果实际上就是将每行每列的值减去了平均值，再除以方差的结果。

我们看到 Z-Score 规范化将数据集进行了规范化，数值都符合均值为 0，方差为 1 的正态分布。

3. 小数定标规范化

我们需要用 NumPy 库来计算小数点的位数。NumPy 库我们之前提到过。

这里我们看下运行代码：

# coding:utf-8


from sklearn import preprocessing


import numpy as np


# 初始化数据

x = np.array([[ 0., -3.,  1.],


              [ 3.,  1.,  2.],


              [ 0.,  1., -1.]])


# 小数定标规范化

j = np.ceil(np.log10(np.max(abs(x))))


scaled_x = x/(10**j)


print scaled_x


运行结果：

[[ 0.  -0.3  0.1]


 [ 0.3  0.1  0.2]


 [ 0.   0.1 -0.1]]


数据挖掘中数据变换比算法选择更重要

在考试成绩中，我们都需要让数据满足一定的规律，达到规范性的要求，便于进行挖掘。这就是数据变换的作用。

如果不进行变换的话，要不就是维数过多，增加了计算的成本，要不就是数据过于集中，很难找到数据之间的特征。

在数据变换中，重点是如何将数值进行规范化，有三种常用的规范方法，分别是 Min-Max 规范化、Z-Score 规范化、小数定标规范化。其中 Z-Score 规范化可以直接将数据转化为正态分布的情况，当然不是所有自然界的数据都需要正态分布，我们也可以根据实际的情况进行设计，比如取对数 log，或者神经网络里采用的激励函数等。

在最后我给大家推荐了 Python 的 sklearn 库，它和 NumPy, Pandas 都是非常有名的 Python 库，在数据统计工作中起了很大的作用。SciKit-Learn 不仅可以用于数据变换，它还提供了分类、聚类、预测等数据挖掘算法的 API 封装。后面我会详细给你讲解这些算法，也会教你如何使用 SciKit-Learn 工具来完成数据挖掘算法的工作。

最后给你留道思考题吧，假设属性 income 的最小值和最大值分别是 5000 元和 58000 元。利用 Min-Max 规范化的方法将属性的值映射到 0 至 1 的范围内，那么属性 income 的 16000 元将被转化为多少？

另外数据规范化都有哪些方式，他们是如何进行规范化的？欢迎在评论区与我分享你的答案，也欢迎你把这篇文章分享给你的朋友或者同事，一起讨论一下。

unpreview


© 版权归极客邦科技所有，未经许可不得传播售卖。页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

大龙

由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。

Command + Enter 发表

0/2000 字

提交留言

精选留言 (41)

锦水春风

老师，你好：

随着学习的不断加深，许多内容需要掌握理解或者编码测试，每个人多少都有疑难问题，如不能及时解决势必影响学习效果。建议对上课人员建立交流 QQ 群，有些问题可以互相交流学习，对仍有问题的老师可亲自回答。

作者回复：咱们有微信群的，可以让运营同学拉你进群

2019-01-13


跳跳

一、16000 的位置

（16000-5000）/（58000-5000）=0.2075


代码实现如下：

# coding:utf-8


from sklearn import preprocessing


import numpy as np


# 初始化数据，每一行表示一个样本，每一列表示一个特征

x = np.array([[5000.],[16000.],[58000.]])


# 将数据进行 [0,1] 规范化

min_max_scaler = preprocessing.MinMaxScaler()


minmax_x = min_max_scaler.fit_transform(x)


print(minmax_x)


输出：

[[0. ]


 [0.20754717]


 [1. ]]


二、关于规范化方法

1.min-max：将数据归一化到 [0,1] 区间

2.z-score：将数据规范到 0 均值，1 方差的标准正态分布上，减少老师说的百分制 80 和 500 分制 80 的数据值差异问题

3. 小数定标规范化：将数据转化为 [-1,1] 区间中

作者回复: Good Job

2019-01-11


杨名流

Min-max 规范化的结果为什么是

[[0. 0. 0.66666667]


 [1. 1. 1. ]


 [0. 1. 0. ]]


这是怎么计算的？

2019-01-20


sunny


老师您好，Z-Score 规范化的分数转化这块，由于我目前在一家公司做产品经理，现在刚好在负责教育行业成绩分析业务，想跟你探讨下。

将学生的原始分数成绩进行转化成 Z 分可以进行比较一个学生历次考试之间的波动情况进步程度，或者是同一次考试的不同科目直接进行比较来判断学生的各科均衡度。

但是，这个「Z-Score」分的计算方式，目前我查到其它资料，老师文章中的列出的计算公式是属于「Z 分的线性计算公式」，将整批学生的成绩都转化成 Z 分后，其 Z 分不一定能完全呈现标准的正态分布，在某些情况下做比较可信度是不高的（比如：一次考试本身的原始分数呈现负偏态，另一次考试原始成绩呈现正偏态，转化后的 Z 分并不一定能让偏态变成标准正态，在两次考试都处于偏态情况下，同一学生的两次考试成绩做波动进步程度分析就不大可信）

我刚查到另一种计算非线性 Z 分的方式：

1、先按该公式计算出百级等级分：百分等级分数（年级）=100﹣（100× 年级名次 - 50）÷ 年级有效参考总人数；该百级等级分便是每个学生在该批学生的相对位置，其百分等级分数对应便是标准正态分布图的所占面积比例

2、再按该百分等级数去标准正态分布表里去查出 Z-Score ，这样最终得出的 Z 分便是标准的正态分布，能将偏态转化成标准正态，这样就能比较同一学生的各次考试

以上是我目前的理解，还望老师指点下！

2019-01-11


Chen


陈老师，有几个问题需要请教一下您：

1. 数据规范化、归一化、标准化是一个概念吗？之前看到有博客还专门区分归一化、标准化，将这里的 Min-max 规范化强调为归一化，将 Z-score 规范化强调为标准化，现在学完这个我有点晕了。看 sklearn 官方文档 Preprocessing data 部分有 4.3.1. Standardization, or mean removal and variance scaling¶ 和 4.3.3 Normalization 两小节内容，看得我更晕了。

2. 一般什么时候用 Min-max 规范化？什么时候用 Z-score 规范化？

3. 数据什么时候需要做规范化呢？

4. 再问细一点的，逻辑回归模型需要做数据规范化吗？决策树模型需要做数据规范化吗？

2019-01-11


柚子

(16000-5000)/(58000-5000) = 0.20754717


代码实现：

import numpy as np


from sklearn import preprocessing


x = np.array([[16000],[5000],[58000]])


minmax_scale = preprocessing.MinMaxScaler().fit_transform(x)


print(minmax_scale)


感觉这块的内容讲的有点浅了 有很多的细节没有讲到 比如 MinMaxScaler ()，fit_transform (x) 这 2 个函数的解释，希望老师可以把 sklearn 库中一些相关函数详细讲解下，谢谢

2019-01-27


林

有时候数据变换比算法选择更重要，数据错了，算法再正确也错的。这就是为什么数据分析师 80% 的时间会花在前期的数据准备上了。

#数据挖掘前的准备工作

在数据变换前，需要对数据进行筛选，然后进行数据探索和相关性分析，接着选择算法模型，然后针对算法模型对数据进行数据变换，从而完成数据挖掘前的准备工作。

#数据变换的四种常见方法

1、数据平滑

去除数据噪声，将连续数据离散化。主要是用分箱、聚类和回归方式等算法进行数据平滑。

2、数据聚集

个人理解就是对数据聚合。

对数据进行汇总，比如常见的使用 sql 的聚合函数。

3、数据概化

个人理解就是数据维度抽象。

将数据由较低的概念抽象成为较高的概念，减少数据复杂度，即用更高的概念替代更低的概念。比如说上海、杭州、深圳、北京可以概化为中国。

4、数据规范化

常用方法：min-max 规范化、Z-score 规范化、按小数定标规范化。

5、属性构造

人个理解就是根据需要加字段。

#数据规范化的几种方法

1、Min-Max 规范化

将原始数据变换到 [0,1] 的空间中。

公式：新数值 =(原数值 - 极小值)/(极大值 - 极小值)

2、Z-score 规范化

对不同级别的数据按相同标准来进行比较。

公式：新数值 = (原数值 - 均值)/ 标准差

3、小数定标规范化

不知道作用是干啥？

    


#Python 的 SciKit-Learn 库

是一个机器学习库，封装了大量的机器学习算法，比如分类、聚类、回归、降维等。另外，它还包括了上面说的数据变换模块。

作者回复: Good Job

2019-01-11


王钰

有些问题可以自己先百度一下，简单了解下函数的用法，不影响继续阅读就可以了

作者回复：嗯嗯

2019-03-11


杰之 7

通过这一节的阅读学习，对数据的转换有了更全面的整理。数据工程师大多数的工作内容也是在处理数据清洗，集成和转换的内容。数据质量能直接影响到后续的算法建模的好坏。

对于常见的变换，有数据平滑、聚集、概化、规范化、属性构造等方法，老师在文章中主要讲述来了规范化的 3 种方法，Min_max 规范化，Z_score，小数立标规范化，并在 sklearn 中加已了实现。

作者回复：加油～

2019-02-11


爬行的蜗牛

(16000-5000)/(58000.0-5000.0)


= 0.20754716981132076


2020-01-16


GS


感觉这章就有一定的跳跃性了，为什么要这么做呢？ 这么做的原因是什么？ 还有没其他方法？感觉没有基础知识储备，有点慌了

作者回复：慢慢来 数据变换在特征过程中用的比较多，可以粗略的了解有几种方法，对每种方法的实现进行复现，然后再追求过程推导的原理

2019-11-18


zart


# coding:utf-8


import numpy as np


from sklearn.preprocessing import MinMaxScaler


minMaxArray = np.array([[5000], [58000]])


scaler = MinMaxScaler()


scaler.fit(minMaxArray)


print(scaler.transform([[16000]]))


作者回复：正确

2019-11-10


Ronnyz


min_max 方法

(16000-5000)/(58000-5000)=0.2075


作者回复：对的

2019-10-31


S.Mona


1. 正态分布是经验归纳结果，自然界惊奇地大多数的分布都形成这么一种分布，再把它命名为正态分布

2. 规范化是 Normalization 么，会不会归一化比较合适？因为我看 ES 权威指南是翻译为归一化

作者回复：是 Normalization，可以翻译成为归一化，就是将数据统一分布情况

2019-10-11


建强

思考题：

属性 income=16000，做 Min-Max 规范化，income=(16000-5000)/(58000-5000) = 0.207547

数据规范化的方式：

(1) Min-Max 规范化，变换公式：新数值 =（原数值 - 极小值）/（极大值 - 极小值）

(2) Z-Score 规范化，变换公式：新数值 =（原数值 - 均值）/ 标准差

(3) 小数定标规范化，通过移动小数点的位置来进行规范化。小数点移动多少位取决于属性的取值中的最大绝对值。

作者回复: Good Job

2019-08-08


twelve


没有理解为什么数据变换不放在数据集成之前？

作者回复：两种方式都可以

2019-07-21


董大琳儿

# coding:utf-8


from sklearn import preprocessing


import numpy as np


# 初始化数据，每一行表示一个样本，每一列表示一个特征

x = np.num（5000,58000）


# 将数据进行 [0,1] 规范化

min_max_scaler = preprocessing.MinMaxScaler()


minmax_x = min_max_scaler.fit_transform(x)


print minmax_x


作者回复: AttributeError: module 'numpy' has no attribute 'num'

2019-06-23


Andre


看到这里我发现，自己什么都不懂，虽然能够理解文章的内容，但是让自己来操作就很困难了

2019-06-05


Geek_7d79b8


不明白为什么非要用 python2

作者回复：后面用 Python3 了

2019-05-16


jk


[min, max] 规范化: (16000-5000) / (58000-5000) = 11/53 ≈ 0.2075

作者回复: Good Job

2019-04-27


滢

ceil () 本身就是 Python 的一个向正无穷取整的函数，np.ceil (np.log10 (np.max (abs (x)))) 得到的是需要将数据整体移动的小数位数。

作者回复：对的

2019-04-12


永降不息之雨

按特征计算啊

2019-03-24


行者

思考题答案：0.20754717

老师，有两个问题：1、在 min-max 转换方法中，如果得到的新数值不在 [0,1] 范围内，那该怎么办？

2、小数点移位转换中，分母是不是最大数值的位数？即 999 是三位数，那么我们是不是就应该除以 1000？希望老师能指点一下。谢谢老师！

2019-03-16


pythonzwd


我觉得有许多函数没有解释什么意思，例如这个 ceil（当然可以自己网上查询） Z-Score 我在书上学到的知识是和标准分，数据分析我觉得统计学的知识还是很重要的，当然这里是用 python ，上一节课在 linux 环境下没有搞好 kettle 的图形界面暂时先跳过了，主要关于老师讲解的内容很多时候有同学又疑问无法得到解答，仅仅写留言是顾及不到的，然后对于他人的留言也无法回复，有个 QQ 群好点至少可以交流

仅仅建议

j = np.ceil(np.log10(np.max(abs(x))))


print(np.log10((np.max(x)))) # =0.47712125471966244


print(j) # =1.0


2019-03-10


周飞

（16000-5000）/（58000-5000）=0.207


作者回复: Good Job

2019-02-27


王彬成

1、假设属性 income 的最小值和最大值分别是 5000 元和 58000 元。利用 Min-Max 规范化的方法将属性的值映射到 0 至 1 的范围内，那么属性 income 的 16000 元将被转化为多少？

计算公式：（16000-5000）/（58000-5000）=0.2075

income 的 16000 元转化为 0.2075

代码实现：

# 初始化数据，每一行表示一个样本，每一列表示一个特征

x=np.array([[5000.],[16000.],[58000.]])


# 将数据进行 [0,1] 规范化

min_max_scaler=preprocessing.MinMaxScaler()


minmax_x=min_max_scaler.fit_transform(x)


print(minmax_x)


2、另外数据规范化都有哪些方式，他们是如何进行规范化的？

数据规范化有 3 种方式：min-max 规范化；Z-score 规范化；小数定标规范化

1）min-max 规范化是对单独每一列进行计算。公式为：新数值 =（原数值 - 极小值）/（极大值 - 极小值）

比如 x=np.array ([[0.,-3.,1.],

            [3.,1.,2.],


            [0.,1.,-1.]


])


会先对第一列 0，3，0 进行计算，然后对第 2 列 - 3，1，1 计算，以此类推

2）Z-score 规范化也是对单独每一列进行计算。公式：新数值 =（原数值 - 均值）/ 标准差

作者回复: Good Job

2019-02-14


bankwc


老师，文中叙述的 min-max 规范化中，应该是最大值和最小值吧，极小值和极大值是局部描述，极小值不一定是最小值，极大值不一定是最大值。请老师点评。

2019-01-30


圆圆的大食客

from sklearn import preprocessing


import numpy as np


x = np.array([[5000.],


              [16000.],


              [58000.]])


min_max_scaler = preprocessing.MinMaxScaler()


minmax_x = min_max_scaler.fit_transform(x)


print (minmax_x)


2019-01-24


李沛欣

今天的看完了。

数据挖掘前的最后步骤。还包括字段过滤，相关性分析，数据探索，算法筛选，数据变换。

数据变换的过程中，有几种类型：数据平滑，数据聚集，数据概化，数据规范化，以及属性构造。

在数据规范化的方法中又有三种：最大最小值，标准差，小数点后位法。

问：假设属性 income 的最小值和最大值分别是 5000 元和 58000 元。利用 Min-Max 规范化的方法将属性的值映射到 0 至 1 的范围内，那么属性 income 的 16000 元将被转化为多少？

答：采用 [0，1] 规范的数据变换后的 income=（原数值 - 极小值）/（极大值 - 极小值 ）= （16000-5000）/（58000-5000）= 0.20754

作者回复: Good Job！

2019-01-24


YTY


@杨名流 我也有这个困惑，后来发现这个是按列计算的。

2019-01-23


胖猫

#mac python3.6


from sklearn import preprocessing


import numpy as np


x = np.array([[5000.],


             [16000.],


             [58000.]])


min_max_x = preprocessing.minmax_scale(X=x)


print(min_max_x)


[[0. ]


 [0.20754717]


 [1. ]]


2019-01-23


Chino


from sklearn import preprocessing


import numpy as np


x = np.array([[58000.],[16000.],[5000.]])


min_max_scale = preprocessing.MinMaxScaler()


result = min_max_scale.fit_transform(x)


print(result)


income_max = 58000


income_min = 5000


income = 16000


print((income - income_min) / (income_max - income_min))


### Max-Min 规格化 每个值减去最小值 再除以 最大值和最小值的差

### Z-score 规格化 每个值减去数学期望 (均值) 再除以方差的开方 (标准差) 等同概率论中求标准正态分布的方法

### 小数定标规格化 找出绝对值最大 根据该数的位数 所有数除以对应的位数

作者回复: Good Job

2019-01-22


你看起来很好吃

老师，有个问题我想先请教下，常用的那些数据处理和机器学习的算法，在解决问题的时候，是使用单一一个算法就能解决问题，还是说需要多种算法配合在一起，来解决实际问题呢，谢谢～

作者回复：都有可能，比如打比赛的时候，可能会采用 ensemble learning 的方式，也就是模型融合

2019-01-14


雨先生的晴天

(16000-5000)/(58000-5000)=0.207


作者回复: Good Job

2019-01-14


wonderland


练习 1：

方法 1：简单直接，直接使用 Min-Max 的原理公式进行规范化：新数值 =（原数值 - 极小值）/（极大值 - 极小值），所以（16000-5000）/（58000-5000）=0.20754716981132076

方法 2：使用 python 中的 sklearn 库，代码如下：

x1 = np.array([[58000.],[16000.],[5000.]])


min_max_scaler1 = preprocessing.MinMaxScaler()


min_max_x1 = min_max_scaler1.fit_transform(x1)


print(min_max_x1)


结果如下：

[[1. ]


 [0.20754717]


[0.]]，第 2 行所对应的数值即为 16000 变换后的数值。

练习 2：数据规范化常见的方法主要有三种：最小最大规范化，z-Score 规范化，小数定标规范化。

-- 最小最大规范化：也叫作特征缩放法，是将原始数据缩放到一个指定的最大和最小值之间，通常是（0,1）之间，计算公式为：新数值 =（原数值 - 极小值）/（极大值 - 极小值）

--z-Score 规范化：将原始数据可以转换为正态分布的数据分布，计算公式为：新数值 = （原数值 - 均值）/ 标准差

-- 小数定标规范化：先取原数据中最大的那个数值，计算他的位数 n，再利用公式：新数值 = 原数值 /（10**n）

作者回复: Good Job

2019-01-13


王 慈

1. (16000－5000)／(58000－5000)=0.208


2. 最小最大值规范化，特点是能将训练集结果框定在 0－1 范围内。Zscore 规范化，特点是将训练集分布假定为正态分布，然后规范化为标准正态分布。小数点定标规范化，特点不知道。

2019-01-12


夏落若

笔记链接：https://mubu.com/doc/b-rDVksSbJ

思考题：(16000 - 5000)/(58000-5000) = 0.2075 即在 [0,1] 的 0.2075 处

疑问：请问小数定标规范化，有哪些应用场景

2019-01-12


卑鄙的我

这些方法的实际使用场景实例举例？

2019-01-11


JingZ


#数据变换

from sklearn import preprocessing


import numpy as np


#初始化数据

min = 5000.


max = 58000.


income = 16000.


x = np.array([[min], [max], [income]])


#将数据 [0 1] 规范化

min_max_scaler = preprocessing.MinMaxScaler()


minmax_x = min_max_scaler.fit_transform(x)


print((minmax_x)[2])


作者回复: Good Job

2019-01-11


林

思考题:

依据公式，新数值 =(原数值 - 极小值)/(极大值 - 极小值)

那么，income 为 16000 时通过 Min-Max 转换后的结果等于

(16000-5000)/(58000-5000)，即是 0.20754716981132

作者回复: Good Job

2019-01-11


許敲敲

(16000-5000)/(58000-5000) 还有个问题 np.ceil 是什么意思

作者回复: ceil 是取整

2019-01-11


收起评论




4176










