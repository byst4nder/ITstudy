# 0304 数据挖掘实战 2：信用卡诈骗分析

陈旸 2019-03-15




11:28


讲述：陈旸 大小：10.52M

上一篇文章中，我们用随机森林以及之前讲过的 SVM、决策树和 KNN 分类器对信用卡违约数据进行了分析，这节课我们来研究下信用卡欺诈。

相比于信用卡违约的比例，信用卡欺诈的比例更小，但是危害极大。如何通过以往的交易数据分析出每笔交易是否正常，是否存在盗刷风险是我们这次项目的目标。

通过今天的学习，你需要掌握以下几个方面：

了解逻辑回归分类，以及如何在 sklearn 中使用它；

信用卡欺诈属于二分类问题，欺诈交易在所有交易中的比例很小，对于这种数据不平衡的情况，到底采用什么样的模型评估标准会更准确；

完成信用卡欺诈分析的实战项目，并通过数据可视化对数据探索和模型结果评估进一步加强了解。

构建逻辑回归分类器

逻辑回归虽然不在我们讲解的十大经典数据挖掘算法里面，但也是常用的数据挖掘算法。

逻辑回归，也叫作 logistic 回归。虽然名字中带有「回归」，但它实际上是分类方法，主要解决的是二分类问题，当然它也可以解决多分类问题，只是二分类更常见一些。

在逻辑回归中使用了 Logistic 函数，也称为 Sigmoid 函数。Sigmoid 函数是在深度学习中经常用到的函数之一，函数公式为：

函数的图形如下所示，类似 S 状：

你能看出 g (z) 的结果在 0-1 之间，当 z 越大的时候，g (z) 越大，当 z 趋近于无穷大的时候，g (z) 趋近于 1。同样当 z 趋近于无穷小的时候，g (z) 趋近于 0。同时，函数值以 0.5 为中心。

为什么逻辑回归算法是基于 Sigmoid 函数实现的呢？你可以这样理解：我们要实现一个二分类任务，0 即为不发生，1 即为发生。我们给定一些历史数据 X 和 y。其中 X 代表样本的 n 个特征，y 代表正例和负例，也就是 0 或 1 的取值。通过历史样本的学习，我们可以得到一个模型，当给定新的 X 的时候，可以预测出 y。这里我们得到的 y 是一个预测的概率，通常不是 0% 和 100%，而是中间的取值，那么我们就可以认为概率大于 50% 的时候，即为发生（正例），概率小于 50% 的时候，即为不发生（负例）。这样就完成了二分类的预测。

逻辑回归模型的求解这里不做介绍，我们来看下如何使用 sklearn 中的逻辑回归工具。在 sklearn 中，我们使用 LogisticRegression () 函数构建逻辑回归分类器，函数里有一些常用的构造参数：

penalty：惩罚项，取值为 l1 或 l2，默认为 l2。当模型参数满足高斯分布的时候，使用 l2，当模型参数满足拉普拉斯分布的时候，使用 l1；

solver：代表的是逻辑回归损失函数的优化方法。有 5 个参数可选，分别为 liblinear、lbfgs、newton-cg、sag 和 saga。默认为 liblinear，适用于数据量小的数据集，当数据量大的时候可以选用 sag 或 saga 方法。

max_iter：算法收敛的最大迭代次数，默认为 10。

n_jobs：拟合和预测的时候 CPU 的核数，默认是 1，也可以是整数，如果是 -1 则代表 CPU 的核数。

当我们创建好之后，就可以使用 fit 函数拟合，使用 predict 函数预测。

模型评估指标

我们之前对模型做评估时，通常采用的是准确率 (accuracy)，它指的是分类器正确分类的样本数与总体样本数之间的比例。这个指标对大部分的分类情况是有效的，不过当分类结果严重不平衡的时候，准确率很难反应模型的好坏。

举个例子，对于机场安检中恐怖分子的判断，就不能采用准确率对模型进行评估。我们知道恐怖分子的比例是极低的，因此当我们用准确率做判断时，如果准确率高达 99.999%，就说明这个模型一定好么？

其实正因为现实生活中恐怖分子的比例极低，就算我们不能识别出一个恐怖分子，也会得到非常高的准确率。因为准确率的评判标准是正确分类的样本个数与总样本数之间的比例。因此非恐怖分子的比例会很高，就算我们识别不出来恐怖分子，正确分类的个数占总样本的比例也会很高，也就是准确率高。

实际上我们应该更关注恐怖分子的识别，这里先介绍下数据预测的四种情况：TP、FP、TN、FN。我们用第二个字母 P 或 N 代表预测为正例还是负例，P 为正，N 为负。第一个字母 T 或 F 代表的是预测结果是否正确，T 为正确，F 为错误。

所以四种情况分别为：

TP：预测为正，判断正确；

FP：预测为正，判断错误；

TN：预测为负，判断正确；

FN：预测为负，判断错误。

我们知道样本总数 =TP+FP+TN+FN，预测正确的样本数为 TP+TN，因此准确率 Accuracy = (TP+TN)/(TP+TN+FN+FP)。

实际上，对于分类不平衡的情况，有两个指标非常重要，它们分别是精确度和召回率。

精确率 P = TP/ (TP+FP)，对应上面恐怖分子这个例子，在所有判断为恐怖分子的人数中，真正是恐怖分子的比例。

召回率 R = TP/ (TP+FN)，也称为查全率。代表的是恐怖分子被正确识别出来的个数与恐怖分子总数的比例。

为什么要统计召回率和精确率这两个指标呢？假设我们只统计召回率，当召回率等于 100% 的时候，模型是否真的好呢？

举个例子，假设我们把机场所有的人都认为是恐怖分子，恐怖分子都会被正确识别，这个数字与恐怖分子的总数比例等于 100%，但是这个结果是没有意义的。如果我们认为机场里所有人都是恐怖分子的话，那么非恐怖分子（极高比例）都会认为是恐怖分子，误判率太高了，所以我们还需要统计精确率作为召回率的补充。

实际上有一个指标综合了精确率和召回率，可以更好地评估模型的好坏。这个指标叫做 F1，用公式表示为：

F1 作为精确率 P 和召回率 R 的调和平均，数值越大代表模型的结果越好。

对信用卡违约率进行分析

我们来看一个信用卡欺诈分析的项目，这个数据集你可以从百度网盘（因为数据集大于 100M，所以采用了网盘）中下载：

链接：https://pan.baidu.com/s/14F8WuX0ZJntdB_r1EC08HA 提取码：58gp

数据集包括了 2013 年 9 月份两天时间内的信用卡交易数据，284807 笔交易中，一共有 492 笔是欺诈行为。输入数据一共包括了 28 个特征 V1，V2，……V28 对应的取值，以及交易时间 Time 和交易金额 Amount。为了保护数据隐私，我们不知道 V1 到 V28 这些特征代表的具体含义，只知道这 28 个特征值是通过 PCA 变换得到的结果。另外字段 Class 代表该笔交易的分类，Class=0 为正常（非欺诈），Class=1 代表欺诈。

我们的目标是针对这个数据集构建一个信用卡欺诈分析的分类器，采用的是逻辑回归。从数据中你能看到欺诈行为只占到了 492/284807=0.172%，数据分类结果的分布是非常不平衡的，因此我们不能使用准确率评估模型的好坏，而是需要统计 F1 值（综合精确率和召回率）。我们先梳理下整个项目的流程：

加载数据；

准备阶段：我们需要探索数据，用数据可视化的方式查看分类结果的情况，以及随着时间的变化，欺诈交易和正常交易的分布情况。上面已经提到过，V1-V28 的特征值都经过 PCA 的变换，但是其余的两个字段，Time 和 Amount 还需要进行规范化。Time 字段和交易本身是否为欺诈交易无关，因此我们不作为特征选择，只需要对 Amount 做数据规范化就行了。同时数据集没有专门的测试集，使用 train_test_split 对数据集进行划分；

分类阶段：我们需要创建逻辑回归分类器，然后传入训练集数据进行训练，并传入测试集预测结果，将预测结果与测试集的结果进行比对。这里的模型评估指标用到了精确率、召回率和 F1 值。同时我们将精确率 - 召回率进行了可视化呈现。

基于上面的流程，具体代码如下：

# -*- coding:utf-8 -*-


# 使用逻辑回归对信用卡欺诈进行分类

import pandas as pd


import numpy as np


import seaborn as sns


import matplotlib.pyplot as plt


import itertools


from sklearn.linear_model import LogisticRegression


from sklearn.model_selection import train_test_split


from sklearn.metrics import confusion_matrix, precision_recall_curve


from sklearn.preprocessing import StandardScaler


import warnings


warnings.filterwarnings('ignore')


 


# 混淆矩阵可视化

def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix"', cmap = plt.cm.Blues) :


    plt.figure()


    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)


    plt.title(title)


    plt.colorbar()


    tick_marks = np.arange(len(classes))


    plt.xticks(tick_marks, classes, rotation = 0)


    plt.yticks(tick_marks, classes)


 


    thresh = cm.max() / 2.


    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :


        plt.text(j, i, cm[i, j],


                 horizontalalignment = 'center',


                 color = 'white' if cm[i, j] > thresh else 'black')


 


    plt.tight_layout()


    plt.ylabel('True label')


    plt.xlabel('Predicted label')


    plt.show()


 


# 显示模型评估结果

def show_metrics():


    tp = cm[1,1]


    fn = cm[1,0]


    fp = cm[0,1]


    tn = cm[0,0]


print (' 精确率: {:.3f}'.format (tp/(tp+fp)))

print (' 召回率: {:.3f}'.format (tp/(tp+fn)))

print ('F1 值: {:.3f}'.format (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn))))))

# 绘制精确率 - 召回率曲线

def plot_precision_recall():


    plt.step(recall, precision, color = 'b', alpha = 0.2, where = 'post')


    plt.fill_between(recall, precision, step ='post', alpha = 0.2, color = 'b')


    plt.plot(recall, precision, linewidth=2)


    plt.xlim([0.0,1])


    plt.ylim([0.0,1.05])


plt.xlabel (' 召回率 ')

plt.ylabel (' 精确率 ')

plt.title (' 精确率 - 召回率 曲线 ')

    plt.show();


 


# 数据加载

data = pd.read_csv('./creditcard.csv')


# 数据探索

print(data.describe())


# 设置 plt 正确显示中文

plt.rcParams['font.sans-serif'] = ['SimHei']


# 绘制类别分布

plt.figure()


ax = sns.countplot(x = 'Class', data = data)


plt.title (' 类别分布 ')

plt.show()


# 显示交易笔数，欺诈交易笔数

num = len(data)


num_fraud = len(data[data['Class']==1]) 


print (' 总交易笔数: ', num)

print (' 诈骗交易笔数：', num_fraud)

print (' 诈骗交易比例：{:.6f}'.format (num_fraud/num))

# 欺诈和正常交易可视化

f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15,8))


bins = 50


ax1.hist(data.Time[data.Class == 1], bins = bins, color = 'deeppink')


ax1.set_title (' 诈骗交易 ')

ax2.hist(data.Time[data.Class == 0], bins = bins, color = 'deepskyblue')


ax2.set_title (' 正常交易 ')

plt.xlabel (' 时间 ')

plt.ylabel (' 交易次数 ')

plt.show()


# 对 Amount 进行数据规范化

data['Amount_Norm'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))


# 特征选择

y = np.array(data.Class.tolist())


data = data.drop(['Time','Amount','Class'],axis=1)


X = np.array(data.as_matrix())


# 准备训练集和测试集

train_x, test_x, train_y, test_y = train_test_split (X, y, test_size = 0.1, random_state = 33)


 


# 逻辑回归分类

clf = LogisticRegression()


clf.fit(train_x, train_y)


predict_y = clf.predict(test_x)


# 预测样本的置信分数

score_y = clf.decision_function(test_x)  


# 计算混淆矩阵，并显示

cm = confusion_matrix(test_y, predict_y)


class_names = [0,1]


# 显示混淆矩阵

plot_confusion_matrix (cm, classes = class_names, title = ' 逻辑回归 混淆矩阵 ')

# 显示模型评估分数

show_metrics()


# 计算精确率，召回率，阈值用于可视化

precision, recall, thresholds = precision_recall_curve(test_y, score_y)


plot_precision_recall()


运行结果：

                Time            V1      ...               Amount          Class


count  284807.000000  2.848070e+05      ...        284807.000000  284807.000000


mean    94813.859575  1.165980e-15      ...            88.349619       0.001727


std     47488.145955  1.958696e+00      ...           250.120109       0.041527


min         0.000000 -5.640751e+01      ...             0.000000       0.000000


25%     54201.500000 -9.203734e-01      ...             5.600000       0.000000


50%     84692.000000  1.810880e-02      ...            22.000000       0.000000


75%    139320.500000  1.315642e+00      ...            77.165000       0.000000


max    172792.000000  2.454930e+00      ...         25691.160000       1.000000


[8 rows x 31 columns]


总交易笔数:  284807

诈骗交易笔数： 492

诈骗交易比例：0.001727

精确率: 0.841

召回率: 0.617

F1 值: 0.712

你能看出来欺诈交易的笔数为 492 笔，占所有交易的比例是很低的，即 0.001727，我们可以通过数据可视化的方式对欺诈交易和正常交易的分布进行呈现。另外通过可视化，我们也能看出精确率和召回率之间的关系，当精确率高的时候，召回率往往很低，召回率高的时候，精确率会比较低。

代码有一些模块需要说明下。

我定义了 plot_confusion_matrix 函数对混淆矩阵进行可视化。什么是混淆矩阵呢？混淆矩阵也叫误差矩阵，实际上它就是 TP、FP、TN、FN 这四个数值的矩阵表示，帮助我们判断预测值和实际值相比，对了多少。从这个例子中，你能看出 TP=37，FP=7，FN=23。所以精确率 P=TP/(TP+FP)=37/(37+7)=0.841，召回率 R=TP/(TP+FN)=37/(37+23)=0.617。

然后使用了 sklearn 中的 precision_recall_curve 函数，通过预测值和真实值来计算精确率 - 召回率曲线。precision_recall_curve 函数会计算在不同概率阈值情况下的精确率和召回率。最后定义 plot_precision_recall 函数，绘制曲线。

总结

今天我给你讲了逻辑回归的概念和相关工具的使用，另外学习了在数据样本不平衡的情况下，如何评估模型。这里你需要了解精确率，召回率和 F1 的概念和计算方式。最后在信用卡欺诈分析的项目中，我们使用了逻辑回归工具，并对混淆矩阵进行了计算，同时在模型结果评估中，使用了精确率、召回率和 F1 值，最后得到精确率 - 召回率曲线的可视化结果。

从这个项目中你能看出来，不是所有的分类都是样本平衡的情况，针对正例比例极低的情况，比如信用卡欺诈、某些疾病的识别，或者是恐怖分子的判断等，都需要采用精确率 - 召回率来进行统计。

最后留两道思考题吧，今天我们对信用卡欺诈数据集进行了分析，它是一个不平衡数据集，你知道还有哪些数据属于不平衡数据么？另外，请你使用线性 SVM（对应 sklearn 中的 LinearSVC）对信用卡欺诈数据集进行分类，并计算精确率、召回率和 F1 值。

欢迎你在评论区与我分享你的答案，也欢迎点击「请朋友读」，把这篇文章分享给你的朋友或者同事。

unpreview


© 版权归极客邦科技所有，未经许可不得传播售卖。页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

大龙

由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。

Command + Enter 发表

0/2000 字

提交留言

精选留言 (21)

白夜

试了下 SVM

精确率: 0.843

召回率: 0.717

F1 值: 0.775

可以通过人的行为（反动言论，购物情况，日常行为）分析预测人群的标签，比如反社会人格，小众爱好者

也可以，反过来通过人的标签（爱喝酒程度，注意力集中度，运动量等）分析人的行为（车祸，罕见疾病的发生）

作者回复: Good Job

2019-03-15


西湖晨曦

继续上面的问题。就是，我就是银行信用卡部的工作人员。假设我通过 fit () 方法得到了信用卡诈骗分析的逻辑回归。假设特征是：性别、收入、是否有房子、是否有车子、是否有助学贷款、是否有公积金这几个特征。我通过 fit () 方法得到了这个有这些特征的逻辑回归曲线。我如何找到每一个特征前面的系数呢？----- 说得直白点，我作为银行信用控制部门工作人员，希望知道上面的特征，哪一个是最重要的，哪一个次重要？哪一个不重要？这样我才能对我的信控工作作出调整。比如我假如知道了是否有助学贷款这个特征不重要，那么我就可以在未来工作中，在银行客户是否允许开信用卡的条件中，取消这个是否有助学贷款的条件，从而给银行信用卡开卡工作带来业务效益。

作者回复：很好的问题，你可以进行分类之后，查看下分类器中特征向量的重要程度，然后进行可视化的呈现，比如我们的分类器是 clf，使用 matplotlib 进行可视化，具体代码如下：

# 显示特征向量的重要程度

coeffs = clf.feature_importances_


df_co = pd.DataFrame(coeffs, columns=["importance_"])


# 下标设置为 Feature Name

df_co.index = train_features.columns


df_co.sort_values("importance_", ascending=True, inplace=True)


df_co.importance_.plot(kind="barh")


plt.title("Feature Importance")


plt.show()


2019-09-14


王彬成

1、使用 LinearSVC 输出的结果：

精确率：0.846

召回率：0.733

F1 值：0.786

2、结果代码，把

# 逻辑回归分类

clf=LogisticRegression()


clf.fit(train_x,train_y)


predict_y=clf.predict(test_x)


更换为：

#线性 SVM 分类

from sklearn import svm


model=svm.LinearSVC()


model.fit(train_x,train_y)


predict_y=model.predict(test_x)


作者回复: Good Job

2019-03-15


一语中的

用 SVM 的 LinearSVC 算法进行分类

精确率：0.846

召回率：0.733

F1 值：0.786

如果 F1 值越大，代表的模型的结果越好，那么 SVM 应该是优于逻辑回归，但是，从计算时间上来看，用逻辑回归算法比用 SVM 要节约 50 多秒（在我本地环境，其他条件不变的情况下）

作者回复: Good Job

2019-03-19


西湖晨曦

对本期的信用卡诈骗分析中，涉及逻辑回归（LogisticRegression）有几点问题，我在网上找了大量资料都找不到答案。特地求助～

1. 逻辑回归数学公式中，求出的值，是介于（0,1）之间。LogisticRegreesion 的 predict () 方法，会设定一个阈值，比如是 0.5，把大于 0.5 的逻辑回归值，设为 1，相反小于 0.5 的，设置为 0。那么我的问题是，为什么要设置 0.5？是固定的吗？如果我希望把阈值 (threshold) 提高到 0.6，如何设置？--- 我看了无数遍 API，就是找不到如何设置这个阈值。

2. 如何看逻辑回归的各个参数。假设我通过 fit () 这个方法对训练集进行训练，得到了逻辑回归的各个 target 的值，即我已经得到了这个逻辑回归的各个参数了。假设有 10 个特征。我如何知道每一个特征前面的变量呢？

作者回复: 0.5 是个阈值，一般做二分类的时候，大于 0.5 可以认为是 1，小于 0.5 认为是 0，=0.5 的时候 可以是 0 或者 1，概率都是一样的

2019-09-14


third


0、所有的小概率事件都属于不平衡数集，比如得某种病，出现车祸或者意外

1、LinearSVC 结果：

精确率：0.845

召回率：0.732

F1 值：0.778

2、结果代码，把

# 逻辑回归分类

clf=LogisticRegression()


clf.fit(train_x,train_y)


predict_y=clf.predict(test_x)


更换为：

#线性 SVM 分类

from sklearn import svm


model=svm.LinearSVC()


model.fit(train_x,train_y)


predict_y=model.predict(test_x)


作者回复: Good Job

2019-03-21


王彬成

逻辑回归混淆矩阵对应的 TP、FP、TN、FN 的位置，以输出的混淆矩阵图为例，

1）首先这四个概念的定义

1. TP：预测为正，判断正确；

2. FP：预测为正，判断错误；

3. TN：预测为负，判断正确；

4. FN：预测为负，判断错误。

2）回归原图

1、predicted=1，True=1，代表预测为正，判断正确，所以 TP=37

2、predicted=1，true=0，代表预测为正，判断错误，所以 FP=7

3、predicted=0，true=1，代表预测为负，判断错误，所以 FN=23

作者回复：总结的不错

2019-03-15


李翔

特征选择中为什么要 drop 掉 amount 这个特征呀？上一步 amount 不是刚标准化嘛？

2020-01-07


Sam. 张朝

我以为程序是判断一笔交易，是否是不正常的。

作者回复：这个是可以判断的

2019-08-09


陈锦榕

***********The evaluation of split test data.*************


Accuracy-Test data: 0.9601


************************************************************************************************************************


Kappa: 0.07924493469331251


************************************************************************************************************************


Confusion matrix,↓real laebl, →predict label」


      0 1


0 9583 397


1 2 18


************************************************************************************************************************


              precision recall f1-score support


           0 1.00 0.96 0.98 9980


           1 0.04 0.90 0.08 20


    accuracy 0.96 10000


   macro avg 0.52 0.93 0.53 10000


weighted avg 1.00 0.96 0.98 10000


作者回复: Good Job 认真做练习的同学

2019-07-30


东东哥

(0, 0) 格子真实值和预测值都为 0，称为预测 Negative 正确，记作 True Negative，简写为 TN。

(0, 1) 格子真实值为 0，但预测值为 1，称为预测 Positive 错误，记作 False Positive，简写为 FP。

(1, 0) 格子真实值为 1，但预测值为 0，称为预测 Negative 错误，记作 False Negative，简写为 FN。

(1, 1) 格子真实值和预测值都为 1，称为预测 Positive 正确，记作 True Positive，简写为 TP。

作者回复：解释正确

2019-07-18


挠头侠

老师 为什么只依靠查准率无法判断模型的好坏呢？我试过很多情况，让我感觉是基本上都可以通过查准率判断模型好坏

2019-06-05


挠头侠

老师 X = np.array (data.as_matrix ()) ，将 dataframe 转化成 ndarray 格式不是必须步骤吧，转化之后是有什么性能上的提升吗？

2019-06-01


华

老师 FN 应该是 28414 吧？

2019-04-11


Lee


好神奇，我之前也做过这个 kaggle 项目，这个是样本不平衡数据集，我当时没做处理的时候误判率好高，后来才有 SMOTE 处理之后才好点，但是看老师这个也没做处理，和我之前的差距好大，还要继续琢磨比对看看我之前错在哪了，当然也希望陈老师能指点一下

2019-03-24


digitarts


老师，我看到，在预测比特币走势的最后一张图表上，实际值与预测值尽管趋势类似，但是在发生的时间上，测试值比实际值晚了一段时间，请问有什么方法尽量缩短这个时间序列的间隙么？多谢🙏

作者回复：不太可能完全吻合

2019-03-24


Destroy、


model = svm.SVC()


model.fit(train_x, train_y)


predict_y = model.predict(test_x)


cm = confusion_matrix(test_y, predict_y)


show_metrics()


精确率：0.953

召回率：0.683

F1 值：0.796

作者回复: Good Job

2019-03-19


白夜

好奇问一下，老师你制作分析图的这个软件是什么？

2019-03-15


一语中的

不平衡数据：

1. 欺诈预测（欺诈的数量远远小于真实交易的数量）

比如，本节内容的信用卡欺诈交易

2. 自然灾害预测（不好的事情远远小于好的事情）

3. 买彩票中奖（小概率）

4. 在图像分类中识别恶性肿瘤（训练样本中含有肿瘤的图像远比没有肿瘤的图像少）

作者回复：很好的分享，不过彩票这个很难预测

2019-03-15


王彬成

不均衡数据集是指，数据集中每个类别下的样本数目相差很大。

比如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）

又如，检查出厂冰箱的合格率，本来合格率就高达了 96%。如果对样本进行检测，准确率也是很高的，那么将会无法判断次品。

再如，检查邮件中的垃圾邮件，因为垃圾邮件占全部邮件极少的部分，所以也是属于不平衡数据集

作者回复：总结的不错

2019-03-15


王彬成

不均衡数据集是指，数据集中每个类别下的样本数目相差很大。

比如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）

又如，检查出厂冰箱的合格率，本来合格率就高达了 96%。如果对样本进行检测，准确率也是很高的，那么将会无法判断次品。

2019-03-15


