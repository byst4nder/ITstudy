Although distinct objects, t1 and t2 compare equal, as expected.

Inspect the identity of the list at t1[-1].

Modify the t1[-1] list in place.

The identity of t1[-1] has not changed, only its value.

t1 and t2 are now different.

This relative immutability of tuples is behind the riddle A += Assignment Puzzler. It’s also the reason why some tuples are unhashable, as we’ve seen in What Is Hashable?.

The distinction between equality and identity has further implications when you need to copy an object. A copy is an equal object with a different ID. But if an object contains other objects, should the copy also duplicate the inner objects, or is it OK to share them? There’s no single answer. Read on for a discussion.

Copies Are Shallow by Default

The easiest way to copy a list (or most built-in mutable collections) is to use the built-in constructor for the type itself. For example:

>>> l1 = [3, [55, 44], (7, 8, 9)] >>> l2 = list(l1) >>> l2 [3, [55, 44], (7, 8, 9)] >>> l2 == l1 True >>> l2 is l1 False

list(l1) creates a copy of l1.

The copies are equal.

But refer to two different objects.

For lists and other mutable sequences, the shortcut l2 = l1[:] also makes a copy.

However, using the constructor or [:] produces a shallow copy (i.e., the outermost container is duplicated, but the copy is filled with references to the same items held by the original container). This saves memory and causes no problems if all the items are immutable. But if there are mutable items, this may lead to unpleasant surprises.

In Example 8-6, we create a shallow copy of a list containing another list and a tuple, and then make changes to see how they affect the referenced objects.

Tip

If you have a connected computer on hand, I highly recommend watching the interactive animation for Example 8-6 at the Online Python Tutor. As I write this, direct linking to a prepared example at pythontutor.com is not working reliably, but the tool is awesome, so taking the time to copy and paste the code is worthwhile.

Example 8-6. Making a shallow copy of a list containing another list; copy and paste this code to see it animated at the Online Python Tutor

l1 = [3, [66, 55, 44], (7, 8, 9)] l2 = list(l1) # l1.append(100) # l1[1].remove(55) # print('l1:', l1) print('l2:', l2) l2[1] += [33, 22] # l2[2] += (10, 11) # print('l1:', l1) print('l2:', l2)

l2 is a shallow copy of l1. This state is depicted in Figure 8-3.

Appending 100 to l1 has no effect on l2.

Here we remove 55 from the inner list l1[1]. This affects l2 because l2[1] is bound to the same list as l1[1].

For a mutable object like the list referred by l2[1], the operator += changes the list in place. This change is visible at l1[1], which is an alias for l2[1].

+= on a tuple creates a new tuple and rebinds the variable l2[2] here. This is the same as doing l2[2] = l2[2] + (10, 11). Now the tuples in the last position of l1 and l2 are no longer the same object. See Figure 8-4.

The output of Example 8-6 is Example 8-7, and the final state of the objects is depicted in Figure 8-4.

Example 8-7. Output of Example 8-6

l1: [3, [66, 44], (7, 8, 9), 100] l2: [3, [66, 44], (7, 8, 9)] l1: [3, [66, 44, 33, 22], (7, 8, 9), 100] l2: [3, [66, 44, 33, 22], (7, 8, 9, 10, 11)]

Figure 8-3. Program state immediately after the assignment l2 = list(l1) in Example 8-6. l1 and l2 refer to distinct lists, but the lists share references to the same inner list object [66, 55, 44] and tuple (7, 8, 9). (Diagram generated by the Online Python Tutor.)

Figure 8-4. Final state of l1 and l2: they still share references to the same list object, now containing [66, 44, 33, 22], but the operation l2[2] += (10, 11) created a new tuple with content (7, 8, 9, 10, 11), unrelated to the tuple (7, 8, 9) referenced by l1[2]. (Diagram generated by the Online Python Tutor.)

It should be clear now that shallow copies are easy to make, but they may or may not be what you want. How to make deep copies is our next topic.

Deep and Shallow Copies of Arbitrary Objects

Working with shallow copies is not always a problem, but sometimes you need to make deep copies (i.e., duplicates that do not share references of embedded objects). The copy module provides the deepcopy and copy functions that return deep and shallow copies of arbitrary objects.

To illustrate the use of copy() and deepcopy(), Example 8-8 defines a simple class, Bus, representing a school bus that is loaded with passengers and then picks up or drops off passengers on its route.

Example 8-8. Bus picks up and drops off passengers

class Bus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name)

Now in the interactive Example 8-9 we will create we will create a bus object (bus1) and two clones—a shallow copy (bus2) and a deep copy (bus3)—to observe what happens as bus1 drops off a student.

Example 8-9. Effects of using copy versus deepcopy

>>> import copy >>> bus1 = Bus(['Alice', 'Bill', 'Claire', 'David']) >>> bus2 = copy.copy(bus1) >>> bus3 = copy.deepcopy(bus1) >>> id(bus1), id(bus2), id(bus3) (4301498296, 4301499416, 4301499752) >>> bus1.drop('Bill') >>> bus2.passengers ['Alice', 'Claire', 'David'] >>> id(bus1.passengers), id(bus2.passengers), id(bus3.passengers) (4302658568, 4302658568, 4302657800) >>> bus3.passengers ['Alice', 'Bill', 'Claire', 'David']

Using copy and deepcopy, we create three distinct Bus instances.

After bus1 drops 'Bill', he is also missing from bus2.

Inspection of the passengers atributes shows that bus1 and bus2 share the same list object, because bus2 is a shallow copy of bus1.

bus3 is a deep copy of bus1, so its passengers attribute refers to another list.

Note that making deep copies is not a simple matter in the general case. Objects may have cyclic references that would cause a naïve algorithm to enter an infinite loop. The deepcopy function remembers the objects already copied to handle cyclic references gracefully. This is demonstrated in Example 8-10.

Example 8-10. Cyclic references: b refers to a, and then is appended to a; deepcopy still manages to copy a

>>> a = [10, 20] >>> b = [a, 30] >>> a.append(b) >>> a [10, 20, [[...], 30]] >>> from copy import deepcopy >>> c = deepcopy(a) >>> c [10, 20, [[...], 30]]

Also, a deep copy may be too deep in some cases. For example, objects may refer to external resources or singletons that should not be copied. You can control the behavior of both copy and deepcopy by implementing the __copy__() and __deepcopy__() special methods as described in the copy module documentation.

The sharing of objects through aliases also explains how parameter passing works in Python, and the problem of using mutable types as parameter defaults. These issues will be covered next.

Function Parameters as References

The only mode of parameter passing in Python is call by sharing. That is the same mode used in most OO languages, including Ruby, SmallTalk, and Java (this applies to Java reference types; primitive types use call by value). Call by sharing means that each formal parameter of the function gets a copy of each reference in the arguments. In other words, the parameters inside the function become aliases of the actual arguments.

The result of this scheme is that a function may change any mutable object passed as a parameter, but it cannot change the identity of those objects (i.e., it cannot altogether replace an object with another). Example 8-11 shows a simple function using += on one of its parameters. As we pass numbers, lists, and tuples to the function, the actual arguments passed are affected in different ways.

Example 8-11. A function may change any mutable object it receives

>>> def f(a, b): ... a += b ... return a ... >>> x = 1 >>> y = 2 >>> f(x, y) 3 >>> x, y (1, 2) >>> a = [1, 2] >>> b = [3, 4] >>> f(a, b) [1, 2, 3, 4] >>> a, b ([1, 2, 3, 4], [3, 4]) >>> t = (10, 20) >>> u = (30, 40) >>> f(t, u) (10, 20, 30, 40) >>> t, u ((10, 20), (30, 40))

The number x is unchanged.

The list a is changed.

The tuple t is unchanged.

Another issue related to function parameters is the use of mutable values for defaults, as discussed next.

Mutable Types as Parameter Defaults: Bad Idea

Optional parameters with default values are a great feature of Python function definitions, allowing our APIs to evolve while remaining backward-compatible. However, you should avoid mutable objects as default values for parameters.

To illustrate this point, in Example 8-12, we take the Bus class from Example 8-8 and change its __init__ method to create HauntedBus. Here we tried to be clever and instead of having a default value of passengers=None, we have passengers=[], thus avoiding the if in the previous __init__. This「cleverness」gets us into trouble.

Example 8-12. A simple class to illustrate the danger of a mutable default

class HauntedBus: """A bus model haunted by ghost passengers""" def __init__(self, passengers=[]): self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name)

When the passengers argument is not passed, this parameter is bound to the default list object, which is initially empty.

This assignment makes self.passengers an alias for passengers, which is itself an alias for the default list, when no passengers argument is given.

When the methods .remove() and .append() are used with self.passengers we are actually mutating the default list, which is an attribute of the function object.

Example 8-13 shows the eerie behavior of the HauntedBus.

Example 8-13. Buses haunted by ghost passengers

>>> bus1 = HauntedBus(['Alice', 'Bill']) >>> bus1.passengers ['Alice', 'Bill'] >>> bus1.pick('Charlie') >>> bus1.drop('Alice') >>> bus1.passengers ['Bill', 'Charlie'] >>> bus2 = HauntedBus() >>> bus2.pick('Carrie') >>> bus2.passengers ['Carrie'] >>> bus3 = HauntedBus() >>> bus3.passengers ['Carrie'] >>> bus3.pick('Dave') >>> bus2.passengers ['Carrie', 'Dave'] >>> bus2.passengers is bus3.passengers True >>> bus1.passengers ['Bill', 'Charlie']

So far, so good: no surprises with bus1.

bus2 starts empty, so the default empty list is assigned to self.passengers.

bus3 also starts empty, again the default list is assigned.

The default is no longer empty!

Now Dave, picked by bus3, appears in bus2.

The problem: bus2.passengers and bus3.passengers refer to the same list.

But bus1.passengers is a distinct list.

The problem is that Bus instances that don’t get an initial passenger list end up sharing the same passenger list among themselves.

Such bugs may be subtle. As Example 8-13 demonstrates, when a HauntedBus is instantiated with passengers, it works as expected. Strange things happen only when a HauntedBus starts empty, because then self.passengers becomes an alias for the default value of the passengers parameter. The problem is that each default value is evaluated when the function is defined—i.e., usually when the module is loaded—and the default values become attributes of the function object. So if a default value is a mutable object, and you change it, the change will affect every future call of the function.

After running the lines in Example 8-13, you can inspect the HauntedBus.__init__ object and see the ghost students haunting its __defaults__ attribute:

>>> dir(HauntedBus.__init__) # doctest: +ELLIPSIS ['__annotations__', '__call__', ..., '__defaults__', ...] >>> HauntedBus.__init__.__defaults__ (['Carrie', 'Dave'],)

Finally, we can verify that bus2.passengers is an alias bound to the first element of the HauntedBus.__init__.__defaults__ attribute:

>>> HauntedBus.__init__.__defaults__[0] is bus2.passengers True

The issue with mutable defaults explains why None is often used as the default value for parameters that may receive mutable values. In Example 8-8, __init__ checks whether the passengers argument is None, and assigns a new empty list to self.passengers. As explained in the following section, if passengers is not None, the correct implementation assigns a copy of it to self.passengers. Let’s now take a closer look.

Defensive Programming with Mutable Parameters

When you are coding a function that receives a mutable parameter, you should carefully consider whether the caller expects the argument passed to be changed.

For example, if your function receives a dict and needs to modify it while processing it, should this side effect be visible outside of the function or not? Actually it depends on the context. It’s really a matter of aligning the expectation of the coder of the function and that of the caller.

The last bus example in this chapter shows how a TwilightBus breaks expectations by sharing its passenger list with its clients. Before studying the implementation, see in Example 8-14 how the TwilightBus class works from the perspective of a client of the class.

Example 8-14. Passengers disappear when dropped by a TwilightBus

>>> basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] >>> bus = TwilightBus(basketball_team) >>> bus.drop('Tina') >>> bus.drop('Pat') >>> basketball_team ['Sue', 'Maya', 'Diana']

basketball_team holds five student names.

A TwilightBus is loaded with the team.

The bus drops one student, then another.

The dropped passengers vanished from the basketball team!

TwilightBus violates the「Principle of least astonishment,」a best practice of interface design. It surely is astonishing that when the bus drops a student, her name is removed from the basketball team roster.

Example 8-15 is the implementation TwilightBus and an explanation of the problem.

Example 8-15. A simple class to show the perils of mutating received arguments

class TwilightBus: """A bus model that makes passengers vanish""" def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name)

Here we are careful to create a new empty list when passengers is None.

However, this assignment makes self.passengers an alias for passengers, which is itself an alias for the actual argument passed to __init__ (i.e.,basketball_team in Example 8-14).

When the methods .remove() and .append() are used with self.passengers, we are actually mutating the original list received as argument to the constructor.

The problem here is that the bus is aliasing the list that is passed to the constructor. Instead, it should keep its own passenger list. The fix is simple: in __init__, when the passengers parameter is provided, self.passengers should be initialized with a copy of it, as we did correctly in Example 8-8 (Deep and Shallow Copies of Arbitrary Objects):

def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers)

Make a copy of the passengers list, or convert it to a list if it’s not one.

Now our internal handling of the passenger list will not affect the argument used to initialize the bus. As a bonus, this solution is more flexible: now the argument passed to the passengers parameter may be a tuple or any other iterable, like a set or even database results, because the list constructor accepts any iterable. As we create our own list to manage, we ensure that it supports the necessary .remove() and .append() operations we use in the .pick() and .drop() methods.

Tip

Unless a method is explicitly intended to mutate an object received as argument, you should think twice before aliasing the argument object by simply assigning it to an instance variable in your class. If in doubt, make a copy. Your clients will often be happier.

del and Garbage Collection

Objects are never explicitly destroyed; however, when they become unreachable they may be garbage-collected.

—「Data Model」chapter of The Python Language Reference

The del statement deletes names, not objects. An object may be garbage collected as result of a del command, but only if the variable deleted holds the last reference to the object, or if the object becomes unreachable.[43] Rebinding a variable may also cause the number of references to an object to reach zero, causing its destruction.

Warning

There is a __del__ special method, but it does not cause the disposal of the instance, and should not be called by your code. __del__ is invoked by the Python interpreter when the instance is about to be destroyed to give it a chance to release external resources. You will seldom need to implement __del__ in your own code, yet some Python beginners spend time coding it for no good reason. The proper use of __del__ is rather tricky. See the __del__ special method documentation in the「Data Model」chapter of The Python Language Reference.

In CPython, the primary algorithm for garbage collection is reference counting. Essentially, each object keeps count of how many references point to it. As soon as that refcount reaches zero, the object is immediately destroyed: CPython calls the __del__ method on the object (if defined) and then frees the memory allocated to the object. In CPython 2.0, a generational garbage collection algorithm was added to detect groups of objects involved in reference cycles—which may be unreachable even with outstanding references to them, when all the mutual references are contained within the group. Other implementations of Python have more sophisticated garbage collectors that do not rely on reference counting, which means the __del__ method may not be called immediately when there are no more references to the object. See「PyPy, Garbage Collection, and a Deadlock」by A. Jesse Jiryu Davis for discussion of improper and proper use of __del__.

To demonstrate the end of an object’s life, Example 8-16 uses weakref.finalize to register a callback function to be called when an object is destroyed.

Example 8-16. Watching the end of an object when no more references point to it

>>> import weakref >>> s1 = {1, 2, 3} >>> s2 = s1 >>> def bye(): ... print('Gone with the wind...') ... >>> ender = weakref.finalize(s1, bye) >>> ender.alive True >>> del s1 >>> ender.alive True >>> s2 = 'spam' Gone with the wind... >>> ender.alive False

s1 and s2 are aliases referring to the same set, {1, 2, 3}.

This function must not be a bound method of the object about to be destroyed or otherwise hold a reference to it.

Register the bye callback on the object referred by s1.

The .alive attribute is True before the finalize object is called.

As discussed, del does not delete an object, just a reference to it.

Rebinding the last reference, s2, makes {1, 2, 3} unreachable. It is destroyed, the bye callback is invoked, and ender.alive becomes False.

The point of Example 8-16 is to make explicit that del does not delete objects, but objects may be deleted as a consequence of being unreachable after del is used.

You may be wondering why the {1, 2, 3} object was destroyed in Example 8-16. After all, the s1 reference was passed to the finalize function, which must have held on to it in order to monitor the object and invoke the callback. This works because finalize holds a weak reference to {1, 2, 3}, as explained in the next section.

Weak References

The presence of references is what keeps an object alive in memory. When the reference count of an object reaches zero, the garbage collector disposes of it. But sometimes it is useful to have a reference to an object that does not keep it around longer than necessary. A common use case is a cache.

Weak references to an object do not increase its reference count. The object that is the target of a reference is called the referent. Therefore, we say that a weak reference does not prevent the referent from being garbage collected.

Weak references are useful in caching applications because you don’t want the cached objects to be kept alive just because they are referenced by the cache.

Example 8-17 shows how a weakref.ref instance can be called to reach its referent. If the object is alive, calling the weak reference returns it, otherwise None is returned.

Tip

Example 8-17 is a console session, and the Python console automatically binds the _ variable to the result of expressions that are not None. This interfered with my intended demonstration but also highlights a practical matter: when trying to micro-manage memory we are often surprised by hidden, implicit assignments that create new references to our objects. The _ console variable is one example. Traceback objects are another common source of unexpected references.

Example 8-17. A weak reference is a callable that returns the referenced object or None if the referent is no more

>>> import weakref >>> a_set = {0, 1} >>> wref = weakref.ref(a_set) >>> wref <weakref at 0x100637598; to 'set' at 0x100636748> >>> wref() {0, 1} >>> a_set = {2, 3, 4} >>> wref() {0, 1} >>> wref() is None False >>> wref() is None True

The wref weak reference object is created and inspected in the next line.

Invoking wref() returns the referenced object, {0, 1}. Because this is a console session, the result {0, 1} is bound to the _ variable.

a_set no longer refers to the {0, 1} set, so its reference count is decreased. But the _ variable still refers to it.

Calling wref() still returns {0, 1}.

When this expression is evaluated, {0, 1} lives, therefore wref() is not None. But _ is then bound to the resulting value, False. Now there are no more strong references to {0, 1}.

Because the {0, 1} object is now gone, this last call to wref() returns None.

The weakref module documentation makes the point that the weakref.ref class is actually a low-level interface intended for advanced uses, and that most programs are better served by the use of the weakref collections and finalize. In other words, consider using WeakKeyDictionary, WeakValueDictionary, WeakSet, and finalize (which use weak references internally) instead of creating and handling your own weakref.ref instances by hand. We just did that in Example 8-17 in the hope that showing a single weakref.ref in action could take away some of the mystery around them. But in practice, most of the time Python programs use the weakref collections.

The next subsection briefly discusses the weakref collections.

The WeakValueDictionary Skit

The class WeakValueDictionary implements a mutable mapping where the values are weak references to objects. When a referred object is garbage collected elsewhere in the program, the corresponding key is automatically removed from WeakValueDictionary. This is commonly used for caching.

Our demonstration of a WeakValueDictionary is inspired by the classic Cheese Shop skit by Monty Python, in which a customer asks for more than 40 kinds of cheese, including cheddar and mozzarella, but none are in stock.[44]

Example 8-18 implements a trivial class to represent each kind of cheese.

Example 8-18. Cheese has a kind attribute and a standard representation

class Cheese: def __init__(self, kind): self.kind = kind def __repr__(self): return 'Cheese(%r)' % self.kind

In Example 8-19, each cheese is loaded from a catalog to a stock implemented as a WeakValueDictionary. However, all but one disappear from the stock as soon as the catalog is deleted. Can you explain why the Parmesan cheese lasts longer than the others?[45] The tip after the code has the answer.

Example 8-19. Customer:「Have you in fact got any cheese here at all?」

>>> import weakref >>> stock = weakref.WeakValueDictionary() >>> catalog = [Cheese('Red Leicester'), Cheese('Tilsit'), ... Cheese('Brie'), Cheese('Parmesan')] ... >>> for cheese in catalog: ... stock[cheese.kind] = cheese ... >>> sorted(stock.keys()) ['Brie', 'Parmesan', 'Red Leicester', 'Tilsit'] >>> del catalog >>> sorted(stock.keys()) ['Parmesan'] >>> del cheese >>> sorted(stock.keys()) []

stock is a WeakValueDictionary.

The stock maps the name of the cheese to a weak reference to the cheese instance in the catalog.

The stock is complete.

After the catalog is deleted, most cheeses are gone from the stock, as expected in WeakValueDictionary. Why not all, in this case?

Tip

A temporary variable may cause an object to last longer than expected by holding a reference to it. This is usually not a problem with local variables: they are destroyed when the function returns. But in Example 8-19, the for loop variable cheese is a global variable and will never go away unless explicitly deleted.

A counterpart to the WeakValueDictionary is the WeakKeyDictionary in which the keys are weak references. The weakref.WeakKeyDictionary documentation hints on possible uses:

[A WeakKeyDictionary] can be used to associate additional data with an object owned by other parts of an application without adding attributes to those objects. This can be especially useful with objects that override attribute accesses.

The weakref module also provides a WeakSet, simply described in the docs as「Set class that keeps weak references to its elements. An element will be discarded when no strong reference to it exists any more.」If you need to build a class that is aware of every one of its instances, a good solution is to create a class attribute with a WeakSet to hold the references to the instances. Otherwise, if a regular set was used, the instances would never be garbage collected, because the class itself would have strong references to them, and classes live as long as the Python process unless you deliberately delete them.

These collections, and weak references in general, are limited in the kinds of objects they can handle. The next section explains.

Limitations of Weak References

Not every Python object may be the target, or referent, of a weak reference. Basic list and dict instances may not be referents, but a plain subclass of either can solve this problem easily:

class MyList(list): """list subclass whose instances may be weakly referenced""" a_list = MyList(range(10)) # a_list can be the target of a weak reference wref_to_a_list = weakref.ref(a_list)

A set instance can be a referent, and that’s why a set was used in Example 8-17. User-defined types also pose no problem, which explains why the silly Cheese class was needed in Example 8-19. But int and tuple instances cannot be targets of weak references, even if subclasses of those types are created.

Most of these limitations are implementation details of CPython that may not apply to other Python iterpreters. They are the result of internal optimizations, some of which are discussed in the following (highly optional) section.

Tricks Python Plays with Immutables

Note

You may safely skip this section. It discusses some Python implementation details that are not really important for users of Python. They are shortcuts and optimizations done by the CPython core developers, which should not bother you when using the language, and that may not apply to other Python implementations or even future versions of CPython. Nevertheless, while experimenting with aliases and copies you may stumble upon these tricks, so I felt they were worth mentioning.

I was surprised to learn that, for a tuple t, t[:] does not make a copy, but returns a reference to the same object. You also get a reference to the same tuple if you write tuple(t).[46] Example 8-20 proves it.

Example 8-20. A tuple built from another is actually the same exact tuple

>>> t1 = (1, 2, 3) >>> t2 = tuple(t1) >>> t2 is t1 True >>> t3 = t1[:] >>> t3 is t1 True

t1 and t2 are bound to the same object.

And so is t3.

The same behavior can be observed with instances of str, bytes, and frozenset. Note that a frozenset is not a sequence, so fs[:] does not work if fs is a frozenset. But fs.copy() has the same effect: it cheats and returns a reference to the same object, and not a copy at all, as Example 8-21 shows.[47]

Example 8-21. String literals may create shared objects

>>> t1 = (1, 2, 3) >>> t3 = (1, 2, 3) # >>> t3 is t1 # False >>> s1 = 'ABC' >>> s2 = 'ABC' # >>> s2 is s1 # True

Creating a new tuple from scratch.

t1 and t3 are equal, but not the same object.

Creating a second str from scratch.

Surprise: a and b refer to the same str!

The sharing of string literals is an optimization technique called interning. CPython uses the same technique with small integers to avoid unnecessary duplication of「popular」numbers like 0, –1, and 42. Note that CPython does not intern all strings or integers, and the criteria it uses to do so is an undocumented implementation detail.

Warning

Never depend on str or int interning! Always use == and not is to compare them for equality. Interning is a feature for internal use of the Python interpreter.

The tricks discussed in this section, including the behavior of frozenset.copy(), are「white lies」; they save memory and make the interpreter faster. Do not worry about them, they should not give you any trouble because they only apply to immutable types. Probably the best use of these bits of trivia is to win bets with fellow Pythonistas.

Chapter Summary

Every Python object has an identity, a type, and a value. Only the value of an object changes over time.[48]

If two variables refer to immutable objects that have equal values (a == b is True), in practice it rarely matters if they refer to copies or are aliases referring to the same object because the value of an immutable object does not change, with one exception. The exception is immutable collections such as tuples and frozensets: if an immutable collection holds references to mutable items, then its value may actually change when the value of a mutable item changes. In practice, this scenario is not so common. What never changes in an immutable collection are the identities of the objects within.

The fact that variables hold references has many practical consequences in Python programming:

Simple assignment does not create copies.

Augmented assignment with += or *= creates new objects if the lefthand variable is bound to an immutable object, but may modify a mutable object in place.

Assigning a new value to an existing variable does not change the object previously bound to it. This is called a rebinding: the variable is now bound to a different object. If that variable was the last reference to the previous object, that object will be garbage collected.

Function parameters are passed as aliases, which means the function may change any mutable object received as an argument. There is no way to prevent this, except making local copies or using immutable objects (e.g., passing a tuple instead of a list).

Using mutable objects as default values for function parameters is dangerous because if the parameters are changed in place, then the default is changed, affecting every future call that relies on the default.

In CPython, objects are discarded as soon as the number of references to them reaches zero. They may also be discarded if they form groups with cyclic references but no outside references. In some situations, it may be useful to hold a reference to an object that will not—by itself—keep an object alive. One example is a class that wants to keep track of all its current instances. This can be done with weak references, a low-level mechanism underlying the more useful collections WeakValueDictionary, WeakKeyDictionary, WeakSet, and the finalize function from the weakref module.

Further Reading

The「Data Model」chapter of The Python Language Reference starts with a clear explanation of object identities and values.

Wesley Chun, author of the Core Python series of books, made a great presentation about many of the topics covered in this chapter during OSCON 2013. You can download the slides from the「Python 103: Memory Model & Best Practices」talk page. There is also a YouTube video of a longer presentation Wesley gave at EuroPython 2011, covering not only the theme of this chapter but also the use of special methods.

Doug Hellmann wrote a long series of excellent blog posts titled Python Module of the Week, which became a book, The Python Standard Library by Example. His posts「copy – Duplicate Objects」and「weakref – Garbage-Collectable References to Objects」cover some of the topics we just discussed.

More information on the CPython generational garbage collector can be found in the gc module documentation, which starts with the sentence「This module provides an interface to the optional garbage collector.」The「optional」qualifier here may be surprising, but the「Data Model」chapter also states:

An implementation is allowed to postpone garbage collection or omit it altogether—it is a matter of implementation quality how garbage collection is implemented, as long as no objects are collected that are still reachable.

Fredrik Lundh—creator of key libraries like ElementTree, Tkinter, and the PIL image library—has a short post about the Python garbage collector titled「How Does Python Manage Memory?」He emphasizes that the garbage collector is an implementation feature that behaves differently across Python interpreters. For example, Jython uses the Java garbage collector.

The CPython 3.4 garbage collector improved handling of objects with a __del__ method, as described in PEP 442 — Safe object finalization.

Wikipedia has an article about string interning, mentioning the use of this technique in several languages, including Python.

Soapbox

Equal Treatment to All Objects

I learned Java before I discovered Python. The == operator in Java never felt right for me. It is much more common for programmers to care about equality than identity, but for objects (not primitive types) the Java == compares references, and not object values. Even for something as basic as comparing strings, Java forces you to use the .equals method. Even then, there is another catch: if you write a.equals(b) and a is null, you get a null pointer exception. The Java designers felt the need to overload + for strings, so why not go ahead and overload == as well?

Python gets this right. The == operator compares object values and is compares references. And because Python has operator overloading, == works sensibly with all objects in the standard library, including None, which is a proper object, unlike Java’s null.

And of course, you can define __eq__ in your own classes to decide what == means for your instances. If you don’t override __eq__, the method inherited from object compares object IDs, so the fallback is that every instance of a user-defined class is considered different.

These are some of the things that made me switch from Java to Python as soon as I finished reading the Python Tutorial one afternoon in September 1998.

Mutability

This chapter would be redundant if all Python objects were immutable. When you are dealing with unchanging objects, it makes no difference whether variables hold the actual objects or references to shared objects. If a == b is true, and neither object can change, they might as well be the same. That’s why string interning is safe. Object identity becomes important only when objects are mutable.

In「pure」functional programming, all data is immutable: appending to a collection actually creates a new collection. Python, however, is not a functional language, much less a pure one. Instances of user-defined classes are mutable by default in Python—as in most object-oriented languages. When creating your own objects, you have to be extra careful to make them immutable, if that is a requirement. Every attribute of the object must also be immutable, otherwise you end up with something like the tuple: immutable as far as object IDs go, but the value of a tuple may change if it holds a mutable object.

Mutable objects are also the main reason why programming with threads is so hard to get right: threads mutating objects without proper synchronization produce corrupted data. Excessive synchronization, on the other hand, causes deadlocks.

Object Destruction and Garbage Collection

There is no mechanism in Python to directly destroy an object, and this omission is actually a great feature: if you could destroy an object at any time, what would happen to existing strong references pointing to it?

Garbage collection in CPython is done primarily by reference counting, which is easy to implement, but is prone to memory leaking when there are reference cycles, so with version 2.0 (October 2000) a generational garbage collector was implemented, and it is able to dispose of unreachable objects kept alive by reference cycles.

But the reference counting is still there as a baseline, and it causes the immediate disposal of objects with zero references. This means that, in CPython—at least for now—it’s safe to write this:

open('test.txt', 'wt', encoding='utf-8').write('1, 2, 3')

That code is safe because the reference count of the file object will be zero after the write method returns, and Python will immediately close the file before destroying the object representing it in memory. However, the same line is not safe in Jython or IronPython that use the garbage collector of their host runtimes (the Java VM and the .NET CLR), which are more sophisticated but do not rely on reference counting and may take longer to destroy the object and close the file. In all cases, including CPython, the best practice is to explicitly close the file, and the most reliable way of doing it is using the with statement, which guarantees that the file will be closed even if exceptions are raised while it is open. Using with, the previous snippet becomes:

with open('test.txt', 'wt', encoding='utf-8') as fp: fp.write('1, 2, 3')

If you are into the subject of garbage collectors, you may want to read Thomas Perl’s paper「Python Garbage Collector Implementations: CPython, PyPy and GaS」, from which I learned the bit about the safety of the open().write() in CPython.

Parameter Passing: Call by Sharing

A popular way of explaining how parameter passing works in Python is the phrase:「Parameters are passed by value, but the values are references.」This not wrong, but causes confusion because the most common parameter passing modes in older languages are call by value (the function gets a copy of the argument) and call by reference (the function gets a pointer to the argument). In Python, the function gets a copy of the arguments, but the arguments are always references. So the value of the referenced objects may be changed, if they are mutable, but their identity cannot. Also, because the function gets a copy of the reference in an argument, rebinding it has no effect outside of the function. I adopted the term call by sharing after reading up on the subject in Programming Language Pragmatics, Third Edition by Michael L. Scott (Morgan Kaufmann), particularly「8.3.1: Parameter Modes.」

The Full Quote of Alice and the Knights’s Song

I love this passage, but it was too long as a chapter opener. So here is the complete dialog about the Knight’s song, its name, and how the song and its name are called:

‘You are sad,’ the Knight said in an anxious tone: ‘let me sing you a song to comfort you.’

‘Is it very long?’ Alice asked, for she had heard a good deal of poetry that day.

‘It’s long,’ said the Knight, ‘but very, VERY beautiful. Everybody that hears me sing it—either it brings the TEARS into their eyes, or else—’

‘Or else what?’ said Alice, for the Knight had made a sudden pause.

‘Or else it doesn’t, you know. The name of the song is called「HADDOCKS’ EYES」.’

‘Oh, that’s the name of the song, is it?’ Alice said, trying to feel interested.

‘No, you don’t understand,’ the Knight said, looking a little vexed. ‘That’s what the name is CALLED. The name really IS「THE AGED AGED MAN」.’

‘Then I ought to have said「That’s what the SONG is called」?’ Alice corrected herself.

‘No, you oughtn’t: that’s quite another thing! The SONG is called「WAYS AND MEANS」: but that’s only what it’s CALLED, you know!’

‘Well, what IS the song, then?’ said Alice, who was by this time completely bewildered.

‘I was coming to that,’ the Knight said. ‘The song really IS「A-SITTING ON A GATE」: and the tune’s my own invention.’

— Lewis Carroll Chapter VIII,「It’s My Own Invention,」Through the Looking-Glass

* * *

[42] On the other hand, single-type sequences like str, bytes, and array.array are flat: they don’t contain references but physically hold their data—characters, bytes, and numbers—in contiguous memory.

[43] If two objects refer to each other, as in Example 8-10, they may be destroyed if the garbage collector determines that they are otherwise unreachable because their only references are their mutual references.

[44] cheeseshop.python.org is also an alias for PyPI—the Python Package Index software repository—which started its life quite empty. At the time of this writing, the Python Cheese Shop has 41,426 packages. Not bad, but still far from the more than 131,000 modules available in CPAN—the Comprehensive Perl Archive Network—the envy of all dynamic language communities.

[45] Parmesan cheese is aged at least a year at the factory, so it is more durable than fresh cheese, but this is not the answer we are looking for.

[46] This is clearly documented. Type help(tuple) in the Python console to read:「If the argument is a tuple, the return value is the same object.」I thought I knew everything about tuples before writing this book.

[47] The white lie of having the copy method not copying anything can be explained by interface compatibility: it makes frozenset more compatible with set. Anyway, it makes no difference to the end user whether two identical immutable objects are the same or are copies.

[48] Actually the type of an object may be changed by merely assigning a different class to its __class__ attribute, but that is pure evil and I regret writing this footnote.

Chapter 9. A Pythonic Object

Never, ever use two leading underscores. This is annoyingly private.[49]

— Ian Bicking Creator of pip, virtualenv, Paste and many other projects

Thanks to the Python data model, your user-defined types can behave as naturally as the built-in types. And this can be accomplished without inheritance, in the spirit of duck typing: you just implement the methods needed for your objects to behave as expected.

In previous chapters, we presented the structure and behavior of many built-in objects. We will now build user-defined classes that behave as real Python objects.

This chapter starts where Chapter 1 ended, by showing how to implement several special methods that are commonly seen in Python objects of many different types.

In this chapter, we will see how to:

Support the built-in functions that produce alternative object representations (e.g., repr(), bytes(), etc).

Implement an alternative constructor as a class method.

Extend the format mini-language used by the format() built-in and the str.format() method.

Provide read-only access to attributes.

Make an object hashable for use in sets and as dict keys.

Save memory with the use of __slots__.

We’ll do all that as we develop a simple two-dimensional Euclidean vector type.

The evolution of the example will be paused to discuss two conceptual topics:

How and when to use the @classmethod and @staticmethod decorators.

Private and protected attributes in Python: usage, conventions, and limitations.

Let’s get started with the object representation methods.

Object Representations

Every object-oriented language has at least one standard way of getting a string representation from any object. Python has two:

repr()

Return a string representing the object as the developer wants to see it.

str()

Return a string representing the object as the user wants to see it.

As you know, we implement the special methods __repr__ and __str__ to support repr() and str().

There are two additional special methods to support alternative representations of objects: __bytes__ and __format__. The __bytes__ method is analogous to __str__: it’s called by bytes() to get the object represented as a byte sequence. Regarding __format__, both the built-in function format() and the str.format() method call it to get string displays of objects using special formatting codes. We’ll cover __bytes__ in the next example, and __format__ after that.

Warning

If you’re coming from Python 2, remember that in Python 3 __repr__, __str__, and __format__ must always return Unicode strings (type str). Only __bytes__ is supposed to return a byte sequence (type bytes).

Vector Class Redux

In order to demonstrate the many methods used to generate object representations, we’ll use a Vector2d class similar to the one we saw in Chapter 1. We will build on it in this and future sections. Example 9-1 illustrates the basic behavior we expect from a Vector2d instance.

Example 9-1. Vector2d instances have several representations

>>> v1 = Vector2d(3, 4) >>> print(v1.x, v1.y) 3.0 4.0 >>> x, y = v1 >>> x, y (3.0, 4.0) >>> v1 Vector2d(3.0, 4.0) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0) >>> octets = bytes(v1) >>> octets b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@' >>> abs(v1) 5.0 >>> bool(v1), bool(Vector2d(0, 0)) (True, False)

The components of a Vector2d can be accessed directly as attributes (no getter method calls).

A Vector2d can be unpacked to a tuple of variables.

The repr of a Vector2d emulates the source code for constructing the instance.

Using eval here shows that the repr of a Vector2d is a faithful representation of its constructor call.[50]

Vector2d supports comparison with ==; this is useful for testing.

print calls str, which for Vector2d produces an ordered pair display.

bytes uses the __bytes__ method to produce a binary representation.

abs uses the __abs__ method to return the magnitude of the Vector2d.

bool uses the __bool__ method to return False for a Vector2d of zero magnitude or True otherwise.

Vector2d from Example 9-1 is implemented in vector2d_v0.py (Example 9-2). The code is based on Example 1-2, but the infix operators will be implemented in Chapter 13—except for == (which is useful for testing). At this point, Vector2d uses several special methods to provide operations that a Pythonista expects in a well-designed object.

Example 9-2. vector2d_v0.py: methods so far are all special methods

from array import array import math class Vector2d: typecode = 'd' def __init__(self, x, y): self.x = float(x) self.y = float(y) def __iter__(self): return (i for i in (self.x, self.y)) def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self))) def __eq__(self, other): return tuple(self) == tuple(other) def __abs__(self): return math.hypot(self.x, self.y) def __bool__(self): return bool(abs(self))

typecode is a class attribute we’ll use when converting Vector2d instances to/from bytes.

Converting x and y to float in __init__ catches errors early, which is helpful in case Vector2d is called with unsuitable arguments.

__iter__ makes a Vector2d iterable; this is what makes unpacking work (e.g, x, y = my_vector). We implement it simply by using a generator expression to yield the components one after the other.[51]

__repr__ builds a string by interpolating the components with {!r} to get their repr; because Vector2d is iterable, *self feeds the x and y components to format.

From an iterable Vector2d, it’s easy to build a tuple for display as an ordered pair.

To generate bytes, we convert the typecode to bytes and concatenate…

…bytes converted from an array built by iterating over the instance.

To quickly compare all components, build tuples out of the operands. This works for operands that are instances of Vector2d, but has issues. See the following warning.

The magnitude is the length of the hypotenuse of the triangle formed by the x and y components.

__bool__ uses abs(self) to compute the magnitude, then converts it to bool, so 0.0 becomes False, nonzero is True.

Warning

Method __eq__ in Example 9-2 works for Vector2d operands but also returns True when comparing Vector2d instances to other iterables holding the same numeric values (e.g., Vector(3, 4) == [3, 4]). This may be considered a feature or a bug. Further discussion needs to wait until Chapter 13, when we cover operator overloading.

We have a fairly complete set of basic methods, but one obvious operation is missing: rebuilding a Vector2d from the binary representation produced by bytes().

An Alternative Constructor

Because we can export a Vector2d as bytes, naturally we need a method that imports a Vector2d from a binary sequence. Looking at the standard library for inspiration, we find that array.array has a class method named .frombytes that suits our purpose—we saw it in Arrays. We adopt its name and use its functionality in a class method for Vector2d in vector2d_v1.py (Example 9-3).

Example 9-3. Part of vector2d_v1.py: this snippet shows only the frombytes class method, added to the Vector2d definition in vector2d_v0.py (Example 9-2)

@classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(*memv)

Class method is modified by the classmethod decorator.

No self argument; instead, the class itself is passed as cls.

Read the typecode from the first byte.

Create a memoryview from the octets binary sequence and use the typecode to cast it.[52]

Unpack the memoryview resulting from the cast into the pair of arguments needed for the constructor.

Because we just used a classmethod decorator, and it is very Python-specific, let’s have a word about it.

classmethod Versus staticmethod

The classmethod decorator is not mentioned in the Python tutorial, and neither is staticmethod. Anyone who has learned OO in Java may wonder why Python has both of these decorators and not just one of them.

Let’s start with classmethod. Example 9-3 shows its use: to define a method that operates on the class and not on instances. classmethod changes the way the method is called, so it receives the class itself as the first argument, instead of an instance. Its most common use is for alternative constructors, like frombytes in Example 9-3. Note how the last line of frombytes actually uses the cls argument by invoking it to build a new instance: cls(*memv). By convention, the first parameter of a class method should be named cls (but Python doesn’t care how it’s named).

In contrast, the staticmethod decorator changes a method so that it receives no special first argument. In essence, a static method is just like a plain function that happens to live in a class body, instead of being defined at the module level. Example 9-4 contrasts the operation of classmethod and staticmethod.

Example 9-4. Comparing behaviors of classmethod and staticmethod

>>> class Demo: ... @classmethod ... def klassmeth(*args): ... return args # ... @staticmethod ... def statmeth(*args): ... return args # ... >>> Demo.klassmeth() # (<class '__main__.Demo'>,) >>> Demo.klassmeth('spam') (<class '__main__.Demo'>, 'spam') >>> Demo.statmeth() # () >>> Demo.statmeth('spam') ('spam',)

klassmeth just returns all positional arguments.

statmeth does the same.

No matter how you invoke it, Demo.klassmeth receives the Demo class as the first argument.

Demo.statmeth behaves just like a plain old function.

Note

The classmethod decorator is clearly useful, but I’ve never seen a compelling use case for staticmethod. If you want to define a function that does not interact with the class, just define it in the module. Maybe the function is closely related even if it never touches the class, so you want to them nearby in the code. Even so, defining the function right before or after the class in the same module is close enough for all practical purposes.[53]

Now that we’ve seen what classmethod is good for (and that staticmethod is not very useful), let’s go back to the issue of object representation and see how to support formatted output.

Formatted Displays

The format() built-in function and the str.format() method delegate the actual formatting to each type by calling their .__format__(format_spec) method. The format_spec is a formatting specifier, which is either:

The second argument in format(my_obj, format_spec), or

Whatever appears after the colon in a replacement field delimited with {} inside a format string used with str.format()

For example:

>>> brl = 1/2.43 # BRL to USD currency conversion rate >>> brl 0.4115226337448559 >>> format(brl, '0.4f') # '0.4115' >>> '1 BRL = {rate:0.2f} USD'.format(rate=brl) # '1 BRL = 0.41 USD'

Formatting specifier is '0.4f'.

Formatting specifier is '0.2f'. The 'rate' substring in the replacement field is called the field name. It’s unrelated to the formatting specifier, but determines which argument of .format() goes into that replacement field.

The second callout makes an important point: a format string such as '{0.mass:5.3e}' actually uses two separate notations. The '0.mass' to the left of the colon is the field_name part of the replacement field syntax; the '5.3e' after the colon is the formatting specifier. The notation used in the formatting specifier is called the Format Specification Mini-Language.

Tip

If format() and str.format() are new to you, classroom experience has shown that it’s best to study the format() function first, which uses just the Format Specification Mini-Language. After you get the gist of that, read Format String Syntax to learn about the {:} replacement field notation, used in the str.format() method (including the !s, !r, and !a conversion flags).

A few built-in types have their own presentation codes in the Format Specification Mini-Language. For example—among several other codes—the int type supports b and x for base 2 and base 16 output, respectively, while float implements f for a fixed-point display and % for a percentage display:

>>> format(42, 'b') '101010' >>> format(2/3, '.1%') '66.7%'

The Format Specification Mini-Language is extensible because each class gets to interpret the format_spec argument as it likes. For instance, the classes in the datetime module use the same format codes in the strftime() functions and in their __format__ methods. Here are a couple examples using the format() built-in and the str.format() method:

>>> from datetime import datetime >>> now = datetime.now() >>> format(now, '%H:%M:%S') '18:49:05' >>> "It's now {:%I:%M %p}".format(now) "It's now 06:49 PM"

If a class has no __format__, the method inherited from object returns str(my_object). Because Vector2d has a __str__, this works:

>>> v1 = Vector2d(3, 4) >>> format(v1) '(3.0, 4.0)'

However, if you pass a format specifier, object.__format__ raises TypeError:

>>> format(v1, '.3f') Traceback (most recent call last): ... TypeError: non-empty format string passed to object.__format__

We will fix that by implementing our own format mini-language. The first step will be to assume the format specifier provided by the user is intended to format each float component of the vector. This is the result we want:

>>> v1 = Vector2d(3, 4) >>> format(v1) '(3.0, 4.0)' >>> format(v1, '.2f') '(3.00, 4.00)' >>> format(v1, '.3e') '(3.000e+00, 4.000e+00)'

Example 9-5 implements __format__ to produce the displays just shown.

Example 9-5. Vector2d.format method, take #1

# inside the Vector2d class def __format__(self, fmt_spec=''): components = (format(c, fmt_spec) for c in self) # return '({}, {})'.format(*components) #

Use the format built-in to apply the fmt_spec to each vector component, building an iterable of formatted strings.

Plug the formatted strings in the formula '(x, y)'.

Now let’s add a custom formatting code to our mini-language: if the format specifier ends with a 'p', we’ll display the vector in polar coordinates: <r, θ>, where r is the magnitude and θ (theta) is the angle in radians. The rest of the format specifier (whatever comes before the 'p') will be used as before.

Tip

When choosing the letter for the custom format code I avoided overlapping with codes used by other types. In Format Specification Mini-Language we see that integers use the codes 'bcdoxXn', floats use 'eEfFgGn%', and strings use 's'. So I picked 'p' for polar coordinates. Because each class interprets these codes independently, reusing a code letter in a custom format for a new type is not an error, but may be confusing to users.

To generate polar coordinates we already have the __abs__ method for the magnitude, and we’ll code a simple angle method using the math.atan2() function to get the angle. This is the code:

# inside the Vector2d class def angle(self): return math.atan2(self.y, self.x)

With that, we can enhance our __format__ to produce polar coordinates. See Example 9-6.

Example 9-6. Vector2d.format method, take #2, now with polar coordinates

def __format__(self, fmt_spec=''): if fmt_spec.endswith('p'): fmt_spec = fmt_spec[:-1] coords = (abs(self), self.angle()) outer_fmt = '<{}, {}>' else: coords = self outer_fmt = '({}, {})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components)

Format ends with 'p': use polar coordinates.

Remove 'p' suffix from fmt_spec.

Build tuple of polar coordinates: (magnitude, angle).

Configure outer format with angle brackets.

Otherwise, use x, y components of self for rectangular coordinates.

Configure outer format with parentheses.

Generate iterable with components as formatted strings.

Plug formatted strings into outer format.

With Example 9-6, we get results similar to these:

>>> format(Vector2d(1, 1), 'p') '<1.4142135623730951, 0.7853981633974483>' >>> format(Vector2d(1, 1), '.3ep') '<1.414e+00, 7.854e-01>' >>> format(Vector2d(1, 1), '0.5fp') '<1.41421, 0.78540>'

As this section shows, it’s not hard to extend the format specification mini-language to support user-defined types.

Now let’s move to a subject that’s not just about appearances: we will make our Vector2d hashable, so we can build sets of vectors, or use them as dict keys. But before we can do that, we must make vectors immutable. We’ll do what it takes next.

A Hashable Vector2d

As defined, so far our Vector2d instances are unhashable, so we can’t put them in a set:

>>> v1 = Vector2d(3, 4) >>> hash(v1) Traceback (most recent call last): ... TypeError: unhashable type: 'Vector2d' >>> set([v1]) Traceback (most recent call last): ... TypeError: unhashable type: 'Vector2d'

To make a Vector2d hashable, we must implement __hash__ (__eq__ is also required, and we already have it). We also need to make vector instances immutable, as we’ve seen in What Is Hashable?.

Right now, anyone can do v1.x = 7 and there is nothing in the code to suggest that changing a Vector2d is forbidden. This is the behavior we want:

>>> v1.x, v1.y (3.0, 4.0) >>> v1.x = 7 Traceback (most recent call last): ... AttributeError: can't set attribute

We’ll do that by making the x and y components read-only properties in Example 9-7.

Example 9-7. vector2d_v3.py: only the changes needed to make Vector2d immutable are shown here; see full listing in Example 9-9

class Vector2d: typecode = 'd' def __init__(self, x, y): self.__x = float(x) self.__y = float(y) @property def x(self): return self.__x @property def y(self): return self.__y def __iter__(self): return (i for i in (self.x, self.y)) # remaining methods follow (omitted in book listing)

Use exactly two leading underscores (with zero or one trailing underscore) to make an attribute private.[54]

The @property decorator marks the getter method of a property.

The getter method is named after the public property it exposes: x.

Just return self.__x.

Repeat same formula for y property.

Every method that just reads the x, y components can stay as they were, reading the public properties via self.x and self.y instead of the private attribute, so this listing omits the rest of the code for the class.

Note

Vector.x and Vector.y are examples of read-only properties. Read/write properties will be covered in Chapter 19, where we dive deeper into the @property.

Now that our vectors are reasonably immutable, we can implement the __hash__ method. It should return an int and ideally take into account the hashes of the object attributes that are also used in the __eq__ method, because objects that compare equal should have the same hash. The __hash__ special method documentation suggests using the bitwise XOR operator (^) to mix the hashes of the components, so that’s what we do. The code for our Vector2d.__hash__ method is really simple, as shown in Example 9-8.

Example 9-8. vector2d_v3.py: implementation of hash

# inside class Vector2d: def __hash__(self): return hash(self.x) ^ hash(self.y)

With the addition of the __hash__ method, we now have hashable vectors:

>>> v1 = Vector2d(3, 4) >>> v2 = Vector2d(3.1, 4.2) >>> hash(v1), hash(v2) (7, 384307168202284039) >>> set([v1, v2]) {Vector2d(3.1, 4.2), Vector2d(3.0, 4.0)}

Tip

It’s not strictly necessary to implement properties or otherwise protect the instance attributes to create a hashable type. Implementing __hash__ and __eq__ correctly is all it takes. But the hash value of an instance is never supposed to change, so this provides an excellent opportunity to talk about read-only properties.

If you are creating a type that has a sensible scalar numeric value, you may also implement the __int__ and __float__ methods, invoked by the int() and float() constructors—which are used for type coercion in some contexts. There’s also a __complex__ method to support the complex() built-in constructor. Perhaps Vector2d should provide __complex__, but I’ll leave that as an exercise for you.

We have been working on Vector2d for a while, showing just snippets, so Example 9-9 is a consolidated, full listing of vector2d_v3.py, including all the doctests I used when developing it.

Example 9-9. vector2d_v3.py: the full monty

""" A two-dimensional vector class >>> v1 = Vector2d(3, 4) >>> print(v1.x, v1.y) 3.0 4.0 >>> x, y = v1 >>> x, y (3.0, 4.0) >>> v1 Vector2d(3.0, 4.0) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0) >>> octets = bytes(v1) >>> octets b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@' >>> abs(v1) 5.0 >>> bool(v1), bool(Vector2d(0, 0)) (True, False) Test of ``.frombytes()`` class method: >>> v1_clone = Vector2d.frombytes(bytes(v1)) >>> v1_clone Vector2d(3.0, 4.0) >>> v1 == v1_clone True Tests of ``format()`` with Cartesian coordinates: >>> format(v1) '(3.0, 4.0)' >>> format(v1, '.2f') '(3.00, 4.00)' >>> format(v1, '.3e') '(3.000e+00, 4.000e+00)' Tests of the ``angle`` method:: >>> Vector2d(0, 0).angle() 0.0 >>> Vector2d(1, 0).angle() 0.0 >>> epsilon = 10**-8 >>> abs(Vector2d(0, 1).angle() - math.pi/2) < epsilon True >>> abs(Vector2d(1, 1).angle() - math.pi/4) < epsilon True Tests of ``format()`` with polar coordinates: >>> format(Vector2d(1, 1), 'p') # doctest:+ELLIPSIS '<1.414213..., 0.785398...>' >>> format(Vector2d(1, 1), '.3ep') '<1.414e+00, 7.854e-01>' >>> format(Vector2d(1, 1), '0.5fp') '<1.41421, 0.78540>' Tests of `x` and `y` read-only properties: >>> v1.x, v1.y (3.0, 4.0) >>> v1.x = 123 Traceback (most recent call last): ... AttributeError: can't set attribute Tests of hashing: >>> v1 = Vector2d(3, 4) >>> v2 = Vector2d(3.1, 4.2) >>> hash(v1), hash(v2) (7, 384307168202284039) >>> len(set([v1, v2])) 2 """ from array import array import math class Vector2d: typecode = 'd' def __init__(self, x, y): self.__x = float(x) self.__y = float(y) @property def x(self): return self.__x @property def y(self): return self.__y def __iter__(self): return (i for i in (self.x, self.y)) def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self))) def __eq__(self, other): return tuple(self) == tuple(other) def __hash__(self): return hash(self.x) ^ hash(self.y) def __abs__(self): return math.hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def angle(self): return math.atan2(self.y, self.x) def __format__(self, fmt_spec=''): if fmt_spec.endswith('p'): fmt_spec = fmt_spec[:-1] coords = (abs(self), self.angle()) outer_fmt = '<{}, {}>' else: coords = self outer_fmt = '({}, {})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components) @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(*memv)

To recap, in this and the previous sections, we saw some essential special methods that you may want to implement to have a full-fledged object. Of course, it is a bad idea to implement all of these methods if your application has no real use for them. Customers don’t care if your objects are「Pythonic」or not.

As coded in Example 9-9, Vector2d is a didactic example with a laundry list of special methods related to object representation, not a template for every user-defined class.

In the next section, we’ll take a break from Vector2d to discuss the design and drawbacks of the private attribute mechanism in Python—the double-underscore prefix in self.__x.

Private and「Protected」Attributes in Python

In Python, there is no way to create private variables like there is with the private modifier in Java. What we have in Python is a simple mechanism to prevent accidental overwriting of a「private」attribute in a subclass.

Consider this scenario: someone wrote a class named Dog that uses a mood instance attribute internally, without exposing it. You need to subclass Dog as Beagle. If you create your own mood instance attribute without being aware of the name clash, you will clobber the mood attribute used by the methods inherited from Dog. This would be a pain to debug.

To prevent this, if you name an instance attribute in the form __mood (two leading underscores and zero or at most one trailing underscore), Python stores the name in the instance __dict__ prefixed with a leading underscore and the class name, so in the Dog class, __mood becomes _Dog__mood, and in Beagle it’s _Beagle__mood. This language feature goes by the lovely name of name mangling.

Example 9-10 shows the result in the Vector2d class from Example 9-7.

Example 9-10. Private attribute names are「mangled」by prefixing the _ and the class name

>>> v1 = Vector2d(3, 4) >>> v1.__dict__ {'_Vector2d__y': 4.0, '_Vector2d__x': 3.0} >>> v1._Vector2d__x 3.0

Name mangling is about safety, not security: it’s designed to prevent accidental access and not intentional wrongdoing (Figure 9-1 illustrates another safety device).

Figure 9-1. A cover on a switch is a safety device, not a security one: it prevents accidental activation, not malicious use

Anyone who knows how private names are mangled can read the private attribute directly, as the last line of Example 9-10 shows—that’s actually useful for debugging and serialization. They can also directly assign a value to a private component of a Vector2d by simply writing v1._Vector__x = 7. But if you are doing that in production code, you can’t complain if something blows up.

The name mangling functionality is not loved by all Pythonistas, and neither is the skewed look of names written as self.__x. Some prefer to avoid this syntax and use just one underscore prefix to「protect」attributes by convention (e.g., self._x). Critics of the automatic double-underscore mangling suggest that concerns about accidental attribute clobbering should be addressed by naming conventions. This is the full quote from the prolific Ian Bicking, cited at the beginning of this chapter:

Never, ever use two leading underscores. This is annoyingly private. If name clashes are a concern, use explicit name mangling instead (e.g., _MyThing_blahblah). This is essentially the same thing as double-underscore, only it’s transparent where double underscore obscures.[55]

The single underscore prefix has no special meaning to the Python interpreter when used in attribute names, but it’s a very strong convention among Python programmers that you should not access such attributes from outside the class.[56] It’s easy to respect the privacy of an object that marks its attributes with a single _, just as it’s easy respect the convention that variables in ALL_CAPS should be treated as constants.

Attributes with a single _ prefix are called「protected」in some corners of the Python documentation.[57] The practice of「protecting」attributes by convention with the form self._x is widespread, but calling that a「protected」attribute is not so common. Some even call that a「private」attribute.

To conclude: the Vector2d components are「private」and our Vector2d instances are「immutable」—with scare quotes—because there is no way to make them really private and immutable.[58]

We’ll now come back to our Vector2d class. In this final section, we cover a special attribute (not a method) that affects the internal storage of an object, with potentially huge impact on the use of memory but little effect on its public interface: __slots__.

Saving Space with the __slots__ Class Attribute

By default, Python stores instance attributes in a per-instance dict named __dict__. As we saw in Practical Consequences of How dict Works, dictionaries have a significant memory overhead because of the underlying hash table used to provide fast access. If you are dealing with millions of instances with few attributes, the __slots__ class attribute can save a lot of memory, by letting the interpreter store the instance attributes in a tuple instead of a dict.

Warning

A __slots__ attribute inherited from a superclass has no effect. Python only takes into account __slots__ attributes defined in each class individually.

To define __slots__, you create a class attribute with that name and assign it an iterable of str with identifiers for the instance attributes. I like to use a tuple for that, because it conveys the message that the __slots__ definition cannot change. See Example 9-11.

Example 9-11. vector2d_v3_slots.py: the slots attribute is the only addition to Vector2d

class Vector2d: __slots__ = ('__x', '__y') typecode = 'd' # methods follow (omitted in book listing)

By defining __slots__ in the class, you are telling the interpreter:「These are all the instance attributes in this class.」Python then stores them in a tuple-like structure in each instance, avoiding the memory overhead of the per-instance __dict__. This can make a huge difference in memory usage if your have millions of instances active at the same time.

Tip

If you are handling millions of objects with numeric data, you should really be using NumPy arrays (see NumPy and SciPy), which are not only memory-efficient but have highly optimized functions for numeric processing, many of which operate on the entire array at once. I designed the Vector2d class just to provide context when discussing special methods, because I try to avoid vague foo and bar examples when I can.

Example 9-12 shows two runs of a script that simply builds a list, using a list comprehension, with 10,000,000 instances of Vector2d. The mem_test.py script takes the name of a module with a Vector2d class variant as command-line argument. In the first run, I am using vector2d_v3.Vector2d (from Example 9-7); in the second run, the __slots__ version of vector2d_v3_slots.Vector2d is used.

Example 9-12. mem_test.py creates 10 million Vector2d instances using the class defined in the named module (e.g., vector2d_v3.py)

